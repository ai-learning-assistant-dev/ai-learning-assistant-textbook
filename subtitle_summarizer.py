#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­—å¹•æ€»ç»“å·¥å…·
è¯»å–SRTå­—å¹•æ–‡ä»¶ï¼Œè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ—¶é—´èŠ‚ç‚¹è¦ç‚¹æ€»ç»“
"""

import json
import os
import re
import argparse
from typing import List, Dict, Tuple
from pathlib import Path

from llm_client import OpenAICompatClient


class SRTParser:
    """SRTå­—å¹•æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def extract_plain_text(file_path: str) -> str:
        """
        ä»SRTæ–‡ä»¶ä¸­æå–çº¯æ–‡æœ¬å†…å®¹ï¼Œå»é™¤æ—¶é—´æ ‡ç­¾å’Œåºå·
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆå¹¶åçš„çº¯æ–‡æœ¬
        """
        subtitles = SRTParser.parse_srt_file(file_path)
        
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        texts = []
        prev_text = ""
        
        for sub in subtitles:
            text = sub['content'].strip()
            
            # å»é™¤ç®—æ³•ç”Ÿæˆæ ‡è®°
            text = re.sub(r'<è¯¥å­—å¹•ç”±ç®—æ³•è‡ªåŠ¨ç”Ÿæˆ>\s*', '', text)
            
            # è·³è¿‡ç©ºæ–‡æœ¬
            if not text:
                continue
            
            # å»é™¤é‡å¤çš„æ–‡æœ¬ï¼ˆå¦‚æœä¸å‰ä¸€å¥å®Œå…¨ç›¸åŒæˆ–è¢«åŒ…å«ï¼‰
            if text == prev_text or (prev_text and text in prev_text):
                continue
            
            texts.append(text)
            prev_text = text
        
        # åˆå¹¶æ–‡æœ¬ï¼Œæ™ºèƒ½æ·»åŠ æ ‡ç‚¹
        merged_text = SRTParser._merge_with_punctuation(texts)
        
        return merged_text
    
    @staticmethod
    def _merge_with_punctuation(texts: List[str]) -> str:
        """
        æ™ºèƒ½åˆå¹¶æ–‡æœ¬å¹¶æ·»åŠ æ ‡ç‚¹ç¬¦å·
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ–‡æœ¬
        """
        if not texts:
            return ""
        
        result = []
        current_sentence = ""
        
        for i, text in enumerate(texts):
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç»“å°¾æ ‡ç‚¹
            has_end_punct = text and text[-1] in 'ã€‚ï¼ï¼Ÿï¼›ï¼Œã€.!?;,'
            
            # å¦‚æœå½“å‰å¥å­ä¸ºç©ºï¼Œç›´æ¥å¼€å§‹æ–°å¥å­
            if not current_sentence:
                current_sentence = text
            else:
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿æ¥è¿˜æ˜¯åˆ†å¥
                # å¦‚æœå‰ä¸€ä¸ªæ–‡æœ¬æœ‰ç»“å°¾æ ‡ç‚¹ï¼Œå¼€å§‹æ–°å¥å­
                if current_sentence[-1] in 'ã€‚ï¼ï¼Ÿ.!?':
                    result.append(current_sentence)
                    current_sentence = text
                # å¦‚æœå½“å‰æ–‡æœ¬æ˜¯è‹±æ–‡å•è¯æˆ–çŸ­è¯­ï¼Œç›´æ¥è¿æ¥
                elif text and (text[0].isupper() or not any('\u4e00' <= c <= '\u9fff' for c in text)):
                    current_sentence += " " + text
                # ä¸­æ–‡å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ æ ‡ç‚¹
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¥å­çš„å»¶ç»­ï¼ˆå¦‚"å•Š"ã€"å‘¢"ã€"çš„"ç­‰ï¼‰
                    if text and len(text) <= 2 and text in ['å•Š', 'å‘¢', 'å§', 'çš„', 'äº†', 'ç€', 'è¿‡', 'å‘ƒ', 'å—¯', 'å“¦']:
                        current_sentence += text
                    # å¦‚æœå‰ä¸€å¥ä»¥é€—å·ã€é¡¿å·ç»“å°¾ï¼Œç›´æ¥è¿æ¥
                    elif current_sentence[-1] in 'ï¼Œã€ï¼›;':
                        current_sentence += text
                    # å¦åˆ™æ·»åŠ é€—å·è¿æ¥
                    else:
                        current_sentence += "ï¼Œ" + text
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå½“å‰å¥å­
            if has_end_punct and text[-1] in 'ã€‚ï¼ï¼Ÿ.!?':
                result.append(current_sentence)
                current_sentence = ""
        
        # æ·»åŠ æœ€åä¸€ä¸ªå¥å­
        if current_sentence:
            # å¦‚æœæ²¡æœ‰ç»“å°¾æ ‡ç‚¹ï¼Œæ·»åŠ å¥å·
            if current_sentence[-1] not in 'ã€‚ï¼ï¼Ÿ.!?':
                current_sentence += "ã€‚"
            result.append(current_sentence)
        
        # åˆå¹¶æˆæ®µè½ï¼Œæ¯3-5å¥ä¸ºä¸€æ®µ
        paragraphs = []
        temp_para = []
        
        for i, sentence in enumerate(result):
            temp_para.append(sentence)
            # æ¯4å¥æˆ–é‡åˆ°æ˜æ˜¾çš„ä¸»é¢˜è½¬æ¢æ ‡å¿—ï¼Œåˆ†æ®µ
            if len(temp_para) >= 4 or (sentence and any(marker in sentence for marker in ['é‚£ä¹ˆ', 'æ¥ä¸‹æ¥', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å', 'æ€»ä¹‹', 'å› æ­¤'])):
                paragraphs.append(''.join(temp_para))
                temp_para = []
        
        if temp_para:
            paragraphs.append(''.join(temp_para))
        
        return '\n\n'.join(paragraphs)
    
    @staticmethod
    def parse_srt_file(file_path: str) -> List[Dict[str, str]]:
        """
        è§£æSRTå­—å¹•æ–‡ä»¶
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—å¹•åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« index, time_start, time_end, content
        """
        subtitles = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰ç©ºè¡Œåˆ†å‰²å­—å¹•å—
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) < 3:
                continue
            
            # ç¬¬ä¸€è¡Œæ˜¯åºå·
            index = lines[0].strip()
            
            # ç¬¬äºŒè¡Œæ˜¯æ—¶é—´è½´
            time_line = lines[1].strip()
            time_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', time_line)
            if not time_match:
                continue
            
            time_start = time_match.group(1)
            time_end = time_match.group(2)
            
            # å‰©ä½™è¡Œæ˜¯å­—å¹•å†…å®¹
            text_content = '\n'.join(lines[2:])
            
            subtitles.append({
                'index': index,
                'time_start': time_start,
                'time_end': time_end,
                'content': text_content
            })
        
        return subtitles
    
    @staticmethod
    def format_subtitles_for_llm(subtitles: List[Dict[str, str]]) -> str:
        """
        å°†å­—å¹•æ ¼å¼åŒ–ä¸ºé€‚åˆLLMå¤„ç†çš„æ–‡æœ¬
        
        Args:
            subtitles: å­—å¹•åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„å­—å¹•æ–‡æœ¬
        """
        formatted_lines = []
        for sub in subtitles:
            formatted_lines.append(f"[{sub['time_start']}] {sub['content']}")
        
        return '\n'.join(formatted_lines)


class SubtitleSummarizer:
    """å­—å¹•æ€»ç»“å™¨"""
    
    def __init__(self, llm_client: OpenAICompatClient):
        """
        åˆå§‹åŒ–æ€»ç»“å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        """
        self.llm_client = llm_client
    
    def create_summary_prompt(self, subtitle_text: str) -> str:
        """
        åˆ›å»ºæ€»ç»“æç¤ºè¯
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            
        Returns:
            æç¤ºè¯
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œæå–å…³é”®è¦ç‚¹å¹¶æŒ‰æ—¶é—´èŠ‚ç‚¹æ€»ç»“ã€‚

è¦æ±‚ï¼š
1. **ç²—ç²’åº¦æ€»ç»“**ï¼šå°†è§†é¢‘åˆ’åˆ†ä¸º3-8ä¸ªä¸»è¦æ®µè½ï¼Œæ¯ä¸ªæ®µè½æ—¶é•¿çº¦3-10åˆ†é’Ÿ
2. æ¯ä¸ªæ®µè½æå–ä¸€ä¸ªå¤§è¦ç‚¹ï¼Œæ¶µç›–è¯¥æ—¶é—´æ®µçš„ä¸»è¦å†…å®¹
3. æ—¶é—´èŠ‚ç‚¹æ ¼å¼ç®€åŒ–ä¸º "MM:SS"ï¼ˆå¦‚ "00:07", "04:28"ï¼‰ï¼Œå–è¯¥æ®µè½å¼€å§‹æ—¶é—´
4. æ ‡é¢˜è¦ç²¾ç‚¼æ¦‚æ‹¬è¯¥æ®µè½çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆ10-20å­—ï¼‰
5. æè¿°è¦è¯¦ç»†å…¨é¢ï¼ˆ100-300å­—ï¼‰ï¼ŒåŒ…å«è¯¥æ®µè½çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ç‚¹ã€ç»†èŠ‚å’Œé€»è¾‘å…³ç³»
6. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
7. **ä¸è¦**è¾“å‡º video_summary å­—æ®µ
8. è¾“å‡ºæ ¼å¼ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ï¼š

```json
{{
  "key_points": [
    {{
      "time": "00:07",
      "title": "è¦ç‚¹æ ‡é¢˜ï¼ˆæ¦‚æ‹¬æ€§å¼ºï¼‰",
      "description": "è¯¦ç»†æè¿°è¯¥æ—¶é—´æ®µçš„æ‰€æœ‰é‡è¦å†…å®¹ï¼ŒåŒ…æ‹¬å…·ä½“ä¿¡æ¯ã€æ•°æ®ã€æ­¥éª¤ã€æ³¨æ„äº‹é¡¹ç­‰ã€‚è¦å°½å¯èƒ½å…¨é¢ï¼Œè®©è¯»è€…æ— éœ€çœ‹è§†é¢‘å°±èƒ½äº†è§£è¿™æ®µå†…å®¹çš„æ ¸å¿ƒçŸ¥è¯†ã€‚"
    }},
    {{
      "time": "04:28",
      "title": "ä¸‹ä¸€ä¸ªè¦ç‚¹æ ‡é¢˜",
      "description": "ç»§ç»­è¯¦ç»†æè¿°..."
    }}
  ]
}}
```

å­—å¹•å†…å®¹ï¼š
{subtitle_text}

è¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼çš„æ€»ç»“ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚æ¯ä¸ªè¦ç‚¹çš„descriptionè¦å……åˆ†è¯¦ç»†ï¼Œæ¶µç›–è¯¥æ—¶é—´æ®µçš„å®Œæ•´å†…å®¹ã€‚"""
        
        return prompt
    
    def summarize(self, subtitle_text: str, stream: bool = False) -> Dict:
        """
        æ€»ç»“å­—å¹•å†…å®¹
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            æ€»ç»“ç»“æœ
        """
        prompt = self.create_summary_prompt(subtitle_text)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–è§†é¢‘å…³é”®ä¿¡æ¯å¹¶è¿›è¡Œç»“æ„åŒ–æ€»ç»“ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        if stream:
            print("æ­£åœ¨ç”Ÿæˆæ€»ç»“ï¼ˆæµå¼è¾“å‡ºï¼‰...\n")
            full_response = ""
            for chunk in self.llm_client.chat_completions_stream(messages):
                print(chunk, end='', flush=True)
                full_response += chunk
            print("\n")
            return self._parse_response(full_response)
        else:
            print("æ­£åœ¨ç”Ÿæˆæ€»ç»“...\n")
            response = self.llm_client.chat_completions(messages)
            content = response['choices'][0]['message']['content']
            return self._parse_response(content)
    
    def _parse_response(self, response_text: str) -> Dict:
        """
        è§£æLLMå“åº”
        
        Args:
            response_text: LLMè¿”å›çš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„JSONå¯¹è±¡
        """
        # å°è¯•æå–JSONéƒ¨åˆ†
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
            json_text = response_text.strip()
        
        try:
            result = json.loads(json_text)
            # ç¡®ä¿åªä¿ç•™ key_points å­—æ®µ
            if 'key_points' in result:
                return {'key_points': result['key_points']}
            return result
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è§£æJSONå“åº”: {e}")
            print(f"åŸå§‹å“åº”ï¼š\n{response_text}\n")
            return {
                "key_points": [],
                "raw_response": response_text
            }
    
    def create_full_content_prompt(self, subtitle_text: str, video_title: str = "") -> str:
        """
        åˆ›å»ºå®Œæ•´å†…å®¹ç”Ÿæˆçš„æç¤ºè¯ï¼ˆæ•™å­¦å¯¼å‘ï¼‰
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            
        Returns:
            æç¤ºè¯
        """
        title_part = f"è§†é¢‘æ ‡é¢˜ï¼š{video_title}\n\n" if video_title else ""
        
        prompt = f"""{title_part}è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘å†…å®¹ï¼Œç¼–å†™ä¸€ä»½**è¯¦ç»†ã€ä¸“ä¸šçš„æ•™å­¦æ–‡æ¡£**ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚è¿™ä»½æ–‡æ¡£å°†ä½œä¸ºå­¦ä¹ èµ„æ–™ï¼Œè¦æ±‚å†…å®¹å®Œæ•´ã€æ˜“äºç†è§£ã€é€‚åˆè‡ªå­¦ã€‚

## æ ¸å¿ƒç›®æ ‡
å°†è§†é¢‘å†…å®¹è½¬åŒ–ä¸º**ç»“æ„åŒ–çš„æ•™å­¦ææ–™**ï¼Œè®©è¯»è€…æ— éœ€è§‚çœ‹è§†é¢‘å³å¯å®Œæ•´æŒæ¡æ‰€æœ‰çŸ¥è¯†ç‚¹ã€‚

## å…·ä½“è¦æ±‚

### ğŸ“š 1. å†…å®¹æ·±åº¦ä¸å®Œæ•´æ€§
- **è¯¦å°½è®²è§£**ï¼šæ¯ä¸ªçŸ¥è¯†ç‚¹éƒ½è¦å……åˆ†å±•å¼€ï¼Œä¸èƒ½åªæ˜¯ç®€å•ç½—åˆ—
- **ä¿ç•™ç»†èŠ‚**ï¼š
  - æ‰€æœ‰æ¦‚å¿µå®šä¹‰å’Œè§£é‡Š
  - å…·ä½“çš„ä¾‹å­ã€æ•°æ®ã€æ¡ˆä¾‹
  - æ–¹æ³•æ­¥éª¤çš„è¯¦ç»†è¯´æ˜
  - æ³¨æ„äº‹é¡¹å’Œå¸¸è§é”™è¯¯
  - ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†
- **é€»è¾‘è¿è´¯**ï¼šè¡¥å……å¿…è¦çš„è¿‡æ¸¡å’Œæ‰¿æ¥ï¼Œä½¿å†…å®¹æµç•…æ˜“è¯»
- **æ·±åº¦é˜è¿°**ï¼šå¯¹é‡è¦æ¦‚å¿µè¿›è¡Œå¤šè§’åº¦è§£é‡Šï¼ˆæ˜¯ä»€ä¹ˆã€ä¸ºä»€ä¹ˆã€æ€ä¹ˆåšã€æ³¨æ„ä»€ä¹ˆï¼‰

### ğŸ—ï¸ 2. æ–‡æ¡£ç»“æ„
- **æ¸…æ™°çš„å±‚çº§**ï¼š
  - ä¸€çº§æ ‡é¢˜ï¼ˆ#ï¼‰ï¼šä¸»è¦ç« èŠ‚
  - äºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ï¼šæ ¸å¿ƒä¸»é¢˜
  - ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰ï¼šå…·ä½“çŸ¥è¯†ç‚¹
  - å››çº§æ ‡é¢˜ï¼ˆ####ï¼‰ï¼šç»†åˆ†å†…å®¹
- **é€»è¾‘é¡ºåº**ï¼šæŒ‰ç…§"å¼•å…¥â†’åŸºç¡€â†’è¿›é˜¶â†’æ€»ç»“"æˆ–è§†é¢‘çš„è‡ªç„¶é¡ºåºç»„ç»‡
- **ç« èŠ‚å®Œæ•´**ï¼šæ¯ä¸ªç« èŠ‚éƒ½åº”åŒ…å«ï¼š
  - æ¦‚å¿µä»‹ç»
  - è¯¦ç»†è¯´æ˜
  - å…·ä½“ç¤ºä¾‹
  - è¦ç‚¹æ€»ç»“

### ğŸ“ 3. æ•™å­¦è¡¨è¾¾æ–¹å¼
- **ä¹¦é¢è¯­**ï¼šå»é™¤å£è¯­åŒ–è¡¨è¾¾ï¼ˆ"å•Š"ã€"å‘ƒ"ã€"é‚£ä¸ª"ç­‰ï¼‰
- **å‡†ç¡®æ€§**ï¼šä½¿ç”¨å‡†ç¡®çš„ä¸“ä¸šæœ¯è¯­ï¼Œå¿…è¦æ—¶åŠ æ³¨è§£
- **æ˜“è¯»æ€§**ï¼š
  - é•¿æ®µè½æ‹†åˆ†ä¸ºå¤šä¸ªå°æ®µè½
  - å¤æ‚æ¦‚å¿µç”¨ç®€å•è¯­è¨€è§£é‡Š
  - é€‚å½“ä½¿ç”¨ç±»æ¯”å’Œæ¯”å–»
- **æ•™å­¦æ€§**ï¼š
  - æå‡ºå¯å‘æ€§é—®é¢˜
  - å¼ºè°ƒé‡ç‚¹å’Œéš¾ç‚¹
  - è¯´æ˜çŸ¥è¯†çš„åº”ç”¨åœºæ™¯

### ğŸ¨ 4. Markdownæ ¼å¼è¿ç”¨
- **ç²—ä½“**ï¼ˆ**æ–‡å­—**ï¼‰ï¼šå…³é”®æ¦‚å¿µã€ä¸“ä¸šæœ¯è¯­ã€é‡ç‚¹å†…å®¹
- **æ–œä½“**ï¼ˆ*æ–‡å­—*ï¼‰ï¼šå¼ºè°ƒã€è¡¥å……è¯´æ˜
- **ä»£ç å—**ï¼ˆ\`ä»£ç \`ï¼‰ï¼šå…¬å¼ã€å‘½ä»¤ã€ä»£ç ç¤ºä¾‹
- **å¼•ç”¨å—**ï¼ˆ> æ–‡å­—ï¼‰ï¼šé‡è¦æç¤ºã€è­¦å‘Šã€å…³é”®ç»“è®º
- **åˆ—è¡¨**ï¼š
  - æ— åºåˆ—è¡¨ï¼ˆ-ï¼‰ï¼šå¹¶åˆ—çš„çŸ¥è¯†ç‚¹ã€ç‰¹å¾
  - æœ‰åºåˆ—è¡¨ï¼ˆ1.ï¼‰ï¼šæ­¥éª¤ã€æµç¨‹ã€æ¡ä»¶
- **è¡¨æ ¼**ï¼šå¯¹æ¯”ã€åˆ†ç±»ã€æ•°æ®å±•ç¤º
- **åˆ†éš”çº¿**ï¼ˆ---ï¼‰ï¼šç« èŠ‚ä¹‹é—´çš„æ˜ç¡®åˆ’åˆ†

### âœ… 5. å†…å®¹ç»„ç»‡åŸåˆ™
- **æ¨¡å—åŒ–**ï¼šæ¯ä¸ªéƒ¨åˆ†ç›¸å¯¹ç‹¬ç«‹ï¼Œä¾¿äºæŸ¥é˜…
- **å¯æ£€ç´¢**ï¼šé‡è¦å†…å®¹æ˜“äºå®šä½å’ŒæŸ¥æ‰¾
- **å¯æ‰©å±•**ï¼šé¢„ç•™ç©ºé—´ç”¨äºç¬”è®°å’Œè¡¥å……
- **å®ç”¨æ€§**ï¼š
  - åŒ…å«å¯æ“ä½œçš„æ–¹æ³•å’Œæ­¥éª¤
  - æä¾›å®é™…åº”ç”¨åœºæ™¯
  - æ€»ç»“å¸¸ç”¨æŠ€å·§å’Œç»éªŒ

### ğŸ“– 6. å»ºè®®çš„æ–‡æ¡£æ¨¡æ¿ç»“æ„

```markdown
# [ä¸»æ ‡é¢˜]

## æ¦‚è¿°/å¼•è¨€
[ç®€è¦è¯´æ˜æœ¬æ–‡æ¡£çš„ä¸»é¢˜ã€ç›®æ ‡ã€é€‚ç”¨å¯¹è±¡]

## åŸºç¡€æ¦‚å¿µ
### æ ¸å¿ƒæ¦‚å¿µ1
[è¯¦ç»†å®šä¹‰ã€è§£é‡Šã€ä¸¾ä¾‹]
### æ ¸å¿ƒæ¦‚å¿µ2
[è¯¦ç»†å®šä¹‰ã€è§£é‡Šã€ä¸¾ä¾‹]

## è¯¦ç»†å†…å®¹
### ä¸»é¢˜1
#### 1.1 å­ä¸»é¢˜
[è¯¦ç»†è®²è§£ã€ä¾‹å­ã€æ³¨æ„äº‹é¡¹]
#### 1.2 å­ä¸»é¢˜
[è¯¦ç»†è®²è§£ã€ä¾‹å­ã€æ³¨æ„äº‹é¡¹]

### ä¸»é¢˜2
...

## å®è·µåº”ç”¨/æ¡ˆä¾‹åˆ†æ
[å…·ä½“ä¾‹å­ã€å®é™…åº”ç”¨åœºæ™¯]

## å¸¸è§é—®é¢˜ä¸æ³¨æ„äº‹é¡¹
[æ˜“é”™ç‚¹ã€å¸¸è§é—®é¢˜ã€è§£å†³æ–¹æ³•]

## æ€»ç»“ä¸è¦ç‚¹å›é¡¾
[æ ¸å¿ƒå†…å®¹æ¢³ç†ã€å…³é”®è¦ç‚¹åˆ—è¡¨]
```

---

**è§†é¢‘åŸæ–‡ï¼ˆå·²é¢„å¤„ç†ï¼‰ï¼š**

{subtitle_text}

---

**è¾“å‡ºè¦æ±‚ï¼š**
1. ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼çš„å®Œæ•´æ•™å­¦æ–‡æ¡£
2. ä¸è¦åŒ…å«"æ ¹æ®è§†é¢‘å†…å®¹"ç­‰å…ƒè¯´æ˜
3. å†…å®¹è¦è¯¦å°½ã€ä¸“ä¸šã€é€‚åˆè‡ªå­¦
4. ç¡®ä¿é€»è¾‘æ¸…æ™°ã€ç»“æ„å®Œæ•´
5. å­—æ•°å……è¶³ï¼ˆé€šå¸¸åº”è¾¾åˆ°åŸå­—å¹•çš„2-3å€ï¼Œå› ä¸ºè¦å±•å¼€å’Œè§£é‡Šï¼‰

è¯·å¼€å§‹ç¼–å†™æ•™å­¦æ–‡æ¡£ï¼š"""
        
        return prompt
    
    def generate_full_content(self, subtitle_text: str, video_title: str = "", stream: bool = False) -> str:
        """
        ç”Ÿæˆå®Œæ•´å†…å®¹æ–‡æ¡£
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            Markdownæ ¼å¼çš„å®Œæ•´å†…å®¹
        """
        prompt = self.create_full_content_prompt(subtitle_text, video_title)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ å†…å®¹æ•´ç†åŠ©æ‰‹ï¼Œæ“…é•¿å°†è§†é¢‘å­—å¹•æ•´ç†æˆç»“æ„æ¸…æ™°ã€å†…å®¹å®Œæ•´çš„å­¦ä¹ æ–‡æ¡£ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        if stream:
            print("æ­£åœ¨ç”Ÿæˆå®Œæ•´å†…å®¹ï¼ˆæµå¼è¾“å‡ºï¼‰...\n")
            full_response = ""
            for chunk in self.llm_client.chat_completions_stream(messages):
                print(chunk, end='', flush=True)
                full_response += chunk
            print("\n")
            return full_response
        else:
            print("æ­£åœ¨ç”Ÿæˆå®Œæ•´å†…å®¹...\n")
            response = self.llm_client.chat_completions(messages)
            content = response['choices'][0]['message']['content']
            return content
    
    def create_exercises_prompt(self, subtitle_text: str, video_title: str = "") -> str:
        """
        åˆ›å»ºç»ƒä¹ é¢˜ç”Ÿæˆçš„æç¤ºè¯
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            
        Returns:
            æç¤ºè¯
        """
        title_part = f"è§†é¢‘æ ‡é¢˜ï¼š{video_title}\n\n" if video_title else ""
        
        prompt = f"""{title_part}è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘å­¦ä¹ å†…å®¹ï¼Œè®¾è®¡ä¸€å¥—ç»ƒä¹ é¢˜ï¼Œç”¨äºå¸®åŠ©å­¦ä¹ è€…æ£€éªŒå’Œå·©å›ºæ‰€å­¦çŸ¥è¯†ã€‚

## é¢˜ç›®è¦æ±‚

### ğŸ“ é€‰æ‹©é¢˜ï¼ˆ5é“ï¼‰
- **è¦†ç›–æ ¸å¿ƒçŸ¥è¯†ç‚¹**ï¼šæ¯é“é¢˜å¯¹åº”ä¸€ä¸ªé‡è¦æ¦‚å¿µæˆ–çŸ¥è¯†ç‚¹
- **éš¾åº¦é€‚ä¸­**ï¼šæ—¢è¦è€ƒæŸ¥ç†è§£ï¼Œä¹Ÿè¦æœ‰ä¸€å®šåŒºåˆ†åº¦
- **é€‰é¡¹è®¾è®¡**ï¼š
  - 4ä¸ªé€‰é¡¹ï¼ˆA/B/C/Dï¼‰
  - æ­£ç¡®ç­”æ¡ˆ1ä¸ª
  - å¹²æ‰°é¡¹è¦æœ‰åˆç†æ€§ï¼ŒåŸºäºå¸¸è§è¯¯è§£
  - é¿å…æ˜æ˜¾é”™è¯¯æˆ–æ— å…³é€‰é¡¹
- **ç­”æ¡ˆè§£æ**ï¼šè¯´æ˜ä¸ºä»€ä¹ˆæ­£ç¡®ï¼Œå…¶ä»–é€‰é¡¹é”™åœ¨å“ªé‡Œ

### âœï¸ ç®€ç­”é¢˜ï¼ˆ5é“ï¼‰
- **æ·±åº¦è€ƒæŸ¥**ï¼šè¦æ±‚å­¦ä¹ è€…ç”¨è‡ªå·±çš„è¯­è¨€é˜è¿°ç†è§£
- **é¢˜å‹å¤šæ ·**ï¼š
  - æ¦‚å¿µè§£é‡Šï¼ˆæ˜¯ä»€ä¹ˆï¼‰
  - åŸå› åˆ†æï¼ˆä¸ºä»€ä¹ˆï¼‰
  - æ–¹æ³•åº”ç”¨ï¼ˆæ€ä¹ˆåšï¼‰
  - å¯¹æ¯”åˆ†æï¼ˆæœ‰ä½•åŒºåˆ«/è”ç³»ï¼‰
  - ç»¼åˆè®ºè¿°ï¼ˆè°ˆè°ˆç†è§£ï¼‰
- **ç­”æ¡ˆè¦ç‚¹**ï¼š
  - åˆ—å‡ºæ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5ç‚¹ï¼‰
  - æ¯ä¸ªè¦ç‚¹æœ‰ç®€è¦è¯´æ˜
  - ç­”æ¡ˆé•¿åº¦é€‚ä¸­ï¼ˆ100-200å­—ï¼‰

## è¾“å‡ºæ ¼å¼

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
  "multiple_choice": [
    {{
      "id": 1,
      "question": "é¢˜ç›®å†…å®¹",
      "options": {{
        "A": "é€‰é¡¹Aå†…å®¹",
        "B": "é€‰é¡¹Bå†…å®¹",
        "C": "é€‰é¡¹Cå†…å®¹",
        "D": "é€‰é¡¹Då†…å®¹"
      }},
      "correct_answer": "A",
      "explanation": "ç­”æ¡ˆè§£æï¼Œè¯´æ˜ä¸ºä»€ä¹ˆAæ­£ç¡®ï¼Œå…¶ä»–é€‰é¡¹ä¸ºä½•é”™è¯¯"
    }}
  ],
  "short_answer": [
    {{
      "id": 1,
      "question": "é¢˜ç›®å†…å®¹",
      "answer_points": [
        "è¦ç‚¹1ï¼šå…·ä½“å†…å®¹",
        "è¦ç‚¹2ï¼šå…·ä½“å†…å®¹",
        "è¦ç‚¹3ï¼šå…·ä½“å†…å®¹"
      ],
      "reference_answer": "å‚è€ƒç­”æ¡ˆçš„å®Œæ•´è¡¨è¿°ï¼ˆ100-200å­—ï¼‰"
    }}
  ]
}}
```

## è®¾è®¡åŸåˆ™

1. **çŸ¥è¯†è¦†ç›–**ï¼šé¢˜ç›®åº”è¦†ç›–è§†é¢‘çš„ä¸»è¦çŸ¥è¯†ç‚¹
2. **å±‚æ¬¡é€’è¿›**ï¼šä»åŸºç¡€åˆ°ç»¼åˆï¼Œç”±æµ…å…¥æ·±
3. **å®ç”¨æ€§**ï¼šé¢˜ç›®è¦æœ‰å®é™…æ„ä¹‰ï¼Œä¸æ˜¯æ­»è®°ç¡¬èƒŒ
4. **å¯æ“ä½œæ€§**ï¼šå­¦ä¹ è€…èƒ½å¤Ÿç‹¬ç«‹å®Œæˆä½œç­”
5. **ç­”æ¡ˆæ˜ç¡®**ï¼šé€‰æ‹©é¢˜ç­”æ¡ˆå”¯ä¸€ï¼Œç®€ç­”é¢˜è¦ç‚¹æ¸…æ™°

---

**å­¦ä¹ å†…å®¹ï¼š**

{subtitle_text}

---

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºç»ƒä¹ é¢˜ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""
        
        return prompt
    
    def generate_exercises(self, subtitle_text: str, video_title: str = "", stream: bool = False) -> Dict:
        """
        ç”Ÿæˆç»ƒä¹ é¢˜
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            åŒ…å«ç»ƒä¹ é¢˜çš„å­—å…¸
        """
        prompt = self.create_exercises_prompt(subtitle_text, video_title)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™è‚²æµ‹è¯„ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®å­¦ä¹ å†…å®¹è®¾è®¡é«˜è´¨é‡çš„ç»ƒä¹ é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        if stream:
            print("æ­£åœ¨ç”Ÿæˆç»ƒä¹ é¢˜ï¼ˆæµå¼è¾“å‡ºï¼‰...\n")
            full_response = ""
            for chunk in self.llm_client.chat_completions_stream(messages):
                print(chunk, end='', flush=True)
                full_response += chunk
            print("\n")
            return self._parse_exercises_response(full_response)
        else:
            print("æ­£åœ¨ç”Ÿæˆç»ƒä¹ é¢˜...\n")
            response = self.llm_client.chat_completions(messages)
            content = response['choices'][0]['message']['content']
            return self._parse_exercises_response(content)
    
    def _parse_exercises_response(self, response_text: str) -> Dict:
        """
        è§£æç»ƒä¹ é¢˜å“åº”
        
        Args:
            response_text: LLMè¿”å›çš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„ç»ƒä¹ é¢˜å­—å…¸
        """
        # å°è¯•æå–JSONéƒ¨åˆ†
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
            json_text = response_text.strip()
        
        try:
            result = json.loads(json_text)
            return result
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è§£æJSONå“åº”: {e}")
            print(f"åŸå§‹å“åº”ï¼š\n{response_text}\n")
            return {
                "multiple_choice": [],
                "short_answer": [],
                "raw_response": response_text
            }
    
    def create_preset_questions_prompt(self, subtitle_text: str, video_title: str = "") -> str:
        """
        åˆ›å»ºé¢„è®¾é—®é¢˜ç”Ÿæˆçš„æç¤ºè¯
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            
        Returns:
            æç¤ºè¯
        """
        title_part = f"è§†é¢‘æ ‡é¢˜ï¼š{video_title}\n\n" if video_title else ""
        
        prompt = f"""{title_part}è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘å†…å®¹ï¼Œè®¾è®¡3ä¸ªé¢„è®¾é—®é¢˜ï¼Œç”¨äºå¼•å¯¼è§‚ä¼—æ€è€ƒè§†é¢‘çš„æ ¸å¿ƒå†…å®¹ã€‚

## é—®é¢˜è¦æ±‚

### ğŸ¯ æ ¸å¿ƒåŸåˆ™
1. **ç®€çŸ­ç²¾ç‚¼**ï¼šæ¯ä¸ªé—®é¢˜æ§åˆ¶åœ¨15-25å­—ä»¥å†…
2. **æ¦‚æ‹¬æ€§å¼º**ï¼šèƒ½å¤ŸæŠ“ä½è§†é¢‘çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®å†…å®¹
3. **å¯å‘æ€è€ƒ**ï¼šå¼•å¯¼è§‚ä¼—ä¸»åŠ¨æ€è€ƒï¼Œè€Œéç®€å•çš„äº‹å®é—®ç­”
4. **é€’è¿›å…³ç³»**ï¼š3ä¸ªé—®é¢˜åº”è¯¥ç”±æµ…å…¥æ·±ï¼Œé€æ­¥æ·±å…¥

### ğŸ“ é—®é¢˜ç±»å‹å»ºè®®
- **é—®é¢˜1**ï¼šæ€»ä½“æŠŠæ¡å‹ - å…³äºæ•´ä½“ä¸»é¢˜ã€æ ¸å¿ƒæ¦‚å¿µ
  - ä¾‹ï¼š"è¿™ä¸ªè§†é¢‘ä¸»è¦è®¨è®ºäº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ"
  - ä¾‹ï¼š"XXçš„æ ¸å¿ƒç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿ"

- **é—®é¢˜2**ï¼šæ·±å…¥ç†è§£å‹ - å…³äºåŸå› ã€æ–¹æ³•ã€å…³ç³»
  - ä¾‹ï¼š"ä¸ºä»€ä¹ˆè¦é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Ÿ"
  - ä¾‹ï¼š"XXå’ŒYYä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ"

- **é—®é¢˜3**ï¼šåº”ç”¨æ‰©å±•å‹ - å…³äºå®è·µã€å¯å‘ã€å»¶ä¼¸
  - ä¾‹ï¼š"å¦‚ä½•å°†è¿™äº›æ–¹æ³•åº”ç”¨åˆ°å®é™…ä¸­ï¼Ÿ"
  - ä¾‹ï¼š"è¿™ä¸ªç†è®ºç»™ä½ å¸¦æ¥äº†ä»€ä¹ˆå¯å‘ï¼Ÿ"

### âš ï¸ æ³¨æ„äº‹é¡¹
- é¿å…è¿‡äºç®€å•çš„æ˜¯éé¢˜
- é¿å…éœ€è¦å¤§é‡èƒŒæ™¯çŸ¥è¯†çš„ä¸“ä¸šé—®é¢˜
- é¿å…è¿‡äºå®½æ³›ã€æ— æ³•èšç„¦çš„é—®é¢˜
- ä¸è¦åŒ…å«ç­”æ¡ˆï¼Œåªæå‡ºé—®é¢˜

## è¾“å‡ºæ ¼å¼

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
  "questions": [
    {{
      "id": 1,
      "question": "ç¬¬ä¸€ä¸ªé¢„è®¾é—®é¢˜çš„å†…å®¹ï¼Ÿ",
      "type": "æ€»ä½“æŠŠæ¡"
    }},
    {{
      "id": 2,
      "question": "ç¬¬äºŒä¸ªé¢„è®¾é—®é¢˜çš„å†…å®¹ï¼Ÿ",
      "type": "æ·±å…¥ç†è§£"
    }},
    {{
      "id": 3,
      "question": "ç¬¬ä¸‰ä¸ªé¢„è®¾é—®é¢˜çš„å†…å®¹ï¼Ÿ",
      "type": "åº”ç”¨æ‰©å±•"
    }}
  ]
}}
```

---

**è§†é¢‘å†…å®¹ï¼š**

{subtitle_text}

---

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡º3ä¸ªé¢„è®¾é—®é¢˜ï¼Œä¸è¦åŒ…å«ç­”æ¡ˆæˆ–å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""
        
        return prompt
    
    def generate_preset_questions(self, subtitle_text: str, video_title: str = "", stream: bool = False) -> Dict:
        """
        ç”Ÿæˆé¢„è®¾é—®é¢˜
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            åŒ…å«é¢„è®¾é—®é¢˜çš„å­—å…¸
        """
        prompt = self.create_preset_questions_prompt(subtitle_text, video_title)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™å­¦è®¾è®¡ä¸“å®¶ï¼Œæ“…é•¿è®¾è®¡èƒ½å¤Ÿå¼•å¯¼å­¦ä¹ è€…æ€è€ƒçš„å¯å‘æ€§é—®é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        if stream:
            print("æ­£åœ¨ç”Ÿæˆé¢„è®¾é—®é¢˜ï¼ˆæµå¼è¾“å‡ºï¼‰...\n")
            full_response = ""
            for chunk in self.llm_client.chat_completions_stream(messages):
                print(chunk, end='', flush=True)
                full_response += chunk
            print("\n")
            return self._parse_questions_response(full_response)
        else:
            print("æ­£åœ¨ç”Ÿæˆé¢„è®¾é—®é¢˜...\n")
            response = self.llm_client.chat_completions(messages)
            content = response['choices'][0]['message']['content']
            return self._parse_questions_response(content)
    
    def _parse_questions_response(self, response_text: str) -> Dict:
        """
        è§£æé¢„è®¾é—®é¢˜å“åº”
        
        Args:
            response_text: LLMè¿”å›çš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„é—®é¢˜å­—å…¸
        """
        # å°è¯•æå–JSONéƒ¨åˆ†
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
            json_text = response_text.strip()
        
        try:
            result = json.loads(json_text)
            return result
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è§£æJSONå“åº”: {e}")
            print(f"åŸå§‹å“åº”ï¼š\n{response_text}\n")
            return {
                "questions": [],
                "raw_response": response_text
            }


def load_llm_config(config_file: str = 'config/llm_models.json', 
                    model_index: int = None, 
                    model_name: str = None) -> Dict:
    """
    åŠ è½½LLMé…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        model_index: ä½¿ç”¨ç¬¬å‡ ä¸ªæ¨¡å‹ï¼ˆç´¢å¼•ï¼Œä»0å¼€å§‹ï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆçº§é«˜äºmodel_indexï¼‰
        
    Returns:
        æ¨¡å‹é…ç½®å­—å…¸
    """
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    models = config.get('models', [])
    if not models:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
    
    # ä¼˜å…ˆä½¿ç”¨model_name
    if model_name:
        for model in models:
            if model.get('name') == model_name:
                print(f"æ‰¾åˆ°æ¨¡å‹: {model_name}")
                return model
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œåˆ—å‡ºå¯ç”¨æ¨¡å‹
        available_names = [m.get('name', 'æœªå‘½å') for m in models]
        raise ValueError(f"æœªæ‰¾åˆ°åä¸º '{model_name}' çš„æ¨¡å‹ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_names)}")
    
    # ä½¿ç”¨model_index
    if model_index is None:
        model_index = 0
    
    if model_index >= len(models):
        print(f"è­¦å‘Šï¼šæ¨¡å‹ç´¢å¼• {model_index} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹")
        model_index = 0
    
    return models[model_index]


def list_available_models(config_file: str = 'config/llm_models.json') -> None:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        models = config.get('models', [])
        if not models:
            print("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
            return
        
        print(f"\nå¯ç”¨çš„æ¨¡å‹ï¼ˆå…± {len(models)} ä¸ªï¼‰ï¼š")
        print("-" * 60)
        for i, model in enumerate(models):
            name = model.get('name', 'æœªå‘½å')
            model_name = model.get('model_name', 'æœªçŸ¥')
            api_base = model.get('api_base', 'æœªçŸ¥')
            print(f"{i}. åç§°: {name}")
            print(f"   æ¨¡å‹: {model_name}")
            print(f"   API: {api_base}")
            print()
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")


def format_output(summary: Dict) -> str:
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    
    Args:
        summary: æ€»ç»“ç»“æœ
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬
    """
    output_lines = []
    output_lines.append("=" * 80)
    output_lines.append("è§†é¢‘å†…å®¹æ€»ç»“")
    output_lines.append("=" * 80)
    output_lines.append("")
    
    # å…³é”®è¦ç‚¹
    key_points = summary.get('key_points', [])
    output_lines.append(f"ğŸ¯ å…³é”®è¦ç‚¹ï¼ˆå…± {len(key_points)} ä¸ªï¼‰ï¼š")
    output_lines.append("")
    
    for i, point in enumerate(key_points, 1):
        time = point.get('time', 'æœªçŸ¥')
        title = point.get('title', 'æ— æ ‡é¢˜')
        description = point.get('description', 'æ— æè¿°')
        
        output_lines.append(f"{i}. [{time}] {title}")
        output_lines.append("")
        # æè¿°å¯èƒ½å¾ˆé•¿ï¼ŒæŒ‰å¥å­æˆ–æ ‡ç‚¹ç¬¦å·åˆ†æ®µæ˜¾ç¤º
        # æ¯è¡Œæœ€å¤š80å­—ç¬¦ï¼Œè‡ªåŠ¨æ¢è¡Œ
        desc_lines = []
        current_line = "   "
        for char in description:
            current_line += char
            if len(current_line) >= 77:  # ç•™3ä¸ªå­—ç¬¦çš„ç¼©è¿›
                # æ‰¾åˆ°æœ€è¿‘çš„æ ‡ç‚¹ç¬¦å·æˆ–ç©ºæ ¼æ¥æ–­è¡Œ
                break_pos = max(
                    current_line.rfind('ã€‚'),
                    current_line.rfind('ï¼Œ'),
                    current_line.rfind('ã€'),
                    current_line.rfind(' ')
                )
                if break_pos > 3:  # ç¡®ä¿ä¸æ˜¯åœ¨å¼€å¤´
                    desc_lines.append(current_line[:break_pos + 1])
                    current_line = "   " + current_line[break_pos + 1:]
                else:
                    desc_lines.append(current_line)
                    current_line = "   "
        
        if current_line.strip():
            desc_lines.append(current_line)
        
        output_lines.extend(desc_lines)
        output_lines.append("")
    
    output_lines.append("=" * 80)
    
    return '\n'.join(output_lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å­—å¹•æ€»ç»“å·¥å…· - ä½¿ç”¨å¤§æ¨¡å‹åˆ†æå­—å¹•å¹¶ç”Ÿæˆè¦ç‚¹æ€»ç»“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
  python subtitle_summarizer.py --list-models
  
  # åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt
  
  # é€šè¿‡åç§°æŒ‡å®šæ¨¡å‹ï¼ˆæ¨èï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -n aivmz8bq80
  
  # é€šè¿‡ç´¢å¼•æŒ‡å®šæ¨¡å‹ï¼ˆ0=ç¬¬ä¸€ä¸ªï¼Œ1=ç¬¬äºŒä¸ªï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -m 1
  
  # ä½¿ç”¨æµå¼è¾“å‡º
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -n aivmz8bq80 --stream
  
  # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -o summary.txt
        """
    )
    
    parser.add_argument('subtitle_file', nargs='?', help='SRTå­—å¹•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--model-index', type=int, default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹ç´¢å¼•ï¼ˆé»˜è®¤ï¼š0ï¼Œå³ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰')
    parser.add_argument('-n', '--model-name', default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆçº§é«˜äº-mï¼‰')
    parser.add_argument('-c', '--config', default='config/llm_models.json',
                       help='LLMé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/llm_models.jsonï¼‰')
    parser.add_argument('-o', '--output', default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šå±å¹•è¾“å‡ºï¼‰')
    parser.add_argument('--stream', action='store_true',
                       help='ä½¿ç”¨æµå¼è¾“å‡º')
    parser.add_argument('--save-json', action='store_true',
                       help='åŒæ—¶ä¿å­˜JSONæ ¼å¼çš„ç»“æœ')
    parser.add_argument('--list-models', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯åˆ—å‡ºæ¨¡å‹
    if args.list_models:
        list_available_models(args.config)
        return
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å­—å¹•æ–‡ä»¶
    if not args.subtitle_file:
        parser.print_help()
        print("\né”™è¯¯ï¼šè¯·æä¾›å­—å¹•æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --list-models æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        return
    
    # æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.subtitle_file):
        print(f"é”™è¯¯ï¼šå­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {args.subtitle_file}")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    try:
        # åŠ è½½LLMé…ç½®
        print(f"åŠ è½½æ¨¡å‹é…ç½®...")
        model_config = load_llm_config(
            args.config, 
            model_index=args.model_index,
            model_name=args.model_name
        )
        print(f"ä½¿ç”¨æ¨¡å‹: {model_config['name']}")
        print(f"APIåœ°å€: {model_config['api_base']}")
        print()
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = OpenAICompatClient(
            api_base=model_config['api_base'],
            api_key=model_config['api_key'],
            default_model=model_config['model_name'],
            request_timeout=300  # æ€»ç»“å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
        )
        
        # è§£æå­—å¹•æ–‡ä»¶
        print(f"è¯»å–å­—å¹•æ–‡ä»¶: {args.subtitle_file}")
        subtitles = SRTParser.parse_srt_file(args.subtitle_file)
        print(f"è§£æåˆ° {len(subtitles)} æ¡å­—å¹•")
        print()
        
        # æ ¼å¼åŒ–å­—å¹•æ–‡æœ¬
        subtitle_text = SRTParser.format_subtitles_for_llm(subtitles)
        
        # åˆ›å»ºæ€»ç»“å™¨å¹¶ç”Ÿæˆæ€»ç»“
        summarizer = SubtitleSummarizer(llm_client)
        summary = summarizer.summarize(subtitle_text, stream=args.stream)
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted_output = format_output(summary)
        
        # è¾“å‡ºåˆ°å±å¹•æˆ–æ–‡ä»¶
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(formatted_output)
            print(f"âœ… æ€»ç»“å·²ä¿å­˜åˆ°: {args.output}")
            
            # å¦‚æœéœ€è¦ä¿å­˜JSON
            if args.save_json:
                json_output = args.output.replace('.txt', '.json')
                with open(json_output, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, ensure_ascii=False, indent=2)
                print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_output}")
        else:
            print(formatted_output)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ä½†è¦ä¿å­˜JSON
        if not args.output and args.save_json:
            subtitle_path = Path(args.subtitle_file)
            json_output = subtitle_path.with_suffix('.summary.json')
            with open(json_output, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_output}")
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

