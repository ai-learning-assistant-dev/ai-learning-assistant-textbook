#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­—å¹•æ€»ç»“å·¥å…·
è¯»å–SRTå­—å¹•æ–‡ä»¶ï¼Œè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ—¶é—´èŠ‚ç‚¹è¦ç‚¹æ€»ç»“
"""

import json
import os
import re
import argparse
from typing import List, Dict, Tuple
from pathlib import Path

from llm_client import OpenAICompatClient


class SRTParser:
    """SRTå­—å¹•æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_srt_file(file_path: str) -> List[Dict[str, str]]:
        """
        è§£æSRTå­—å¹•æ–‡ä»¶
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            å­—å¹•åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« index, time_start, time_end, content
        """
        subtitles = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰ç©ºè¡Œåˆ†å‰²å­—å¹•å—
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) < 3:
                continue
            
            # ç¬¬ä¸€è¡Œæ˜¯åºå·
            index = lines[0].strip()
            
            # ç¬¬äºŒè¡Œæ˜¯æ—¶é—´è½´
            time_line = lines[1].strip()
            time_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', time_line)
            if not time_match:
                continue
            
            time_start = time_match.group(1)
            time_end = time_match.group(2)
            
            # å‰©ä½™è¡Œæ˜¯å­—å¹•å†…å®¹
            text_content = '\n'.join(lines[2:])
            
            subtitles.append({
                'index': index,
                'time_start': time_start,
                'time_end': time_end,
                'content': text_content
            })
        
        return subtitles
    
    @staticmethod
    def format_subtitles_for_llm(subtitles: List[Dict[str, str]]) -> str:
        """
        å°†å­—å¹•æ ¼å¼åŒ–ä¸ºé€‚åˆLLMå¤„ç†çš„æ–‡æœ¬
        
        Args:
            subtitles: å­—å¹•åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„å­—å¹•æ–‡æœ¬
        """
        formatted_lines = []
        for sub in subtitles:
            formatted_lines.append(f"[{sub['time_start']}] {sub['content']}")
        
        return '\n'.join(formatted_lines)


class SubtitleSummarizer:
    """å­—å¹•æ€»ç»“å™¨"""
    
    def __init__(self, llm_client: OpenAICompatClient):
        """
        åˆå§‹åŒ–æ€»ç»“å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        """
        self.llm_client = llm_client
    
    def create_summary_prompt(self, subtitle_text: str) -> str:
        """
        åˆ›å»ºæ€»ç»“æç¤ºè¯
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            
        Returns:
            æç¤ºè¯
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œæå–å…³é”®è¦ç‚¹å¹¶æŒ‰æ—¶é—´èŠ‚ç‚¹æ€»ç»“ã€‚

è¦æ±‚ï¼š
1. **ç²—ç²’åº¦æ€»ç»“**ï¼šå°†è§†é¢‘åˆ’åˆ†ä¸º3-8ä¸ªä¸»è¦æ®µè½ï¼Œæ¯ä¸ªæ®µè½æ—¶é•¿çº¦3-10åˆ†é’Ÿ
2. æ¯ä¸ªæ®µè½æå–ä¸€ä¸ªå¤§è¦ç‚¹ï¼Œæ¶µç›–è¯¥æ—¶é—´æ®µçš„ä¸»è¦å†…å®¹
3. æ—¶é—´èŠ‚ç‚¹æ ¼å¼ç®€åŒ–ä¸º "MM:SS"ï¼ˆå¦‚ "00:07", "04:28"ï¼‰ï¼Œå–è¯¥æ®µè½å¼€å§‹æ—¶é—´
4. æ ‡é¢˜è¦ç²¾ç‚¼æ¦‚æ‹¬è¯¥æ®µè½çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆ10-20å­—ï¼‰
5. æè¿°è¦è¯¦ç»†å…¨é¢ï¼ˆ100-300å­—ï¼‰ï¼ŒåŒ…å«è¯¥æ®µè½çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ç‚¹ã€ç»†èŠ‚å’Œé€»è¾‘å…³ç³»
6. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
7. **ä¸è¦**è¾“å‡º video_summary å­—æ®µ
8. è¾“å‡ºæ ¼å¼ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ï¼š

```json
{{
  "key_points": [
    {{
      "time": "00:07",
      "title": "è¦ç‚¹æ ‡é¢˜ï¼ˆæ¦‚æ‹¬æ€§å¼ºï¼‰",
      "description": "è¯¦ç»†æè¿°è¯¥æ—¶é—´æ®µçš„æ‰€æœ‰é‡è¦å†…å®¹ï¼ŒåŒ…æ‹¬å…·ä½“ä¿¡æ¯ã€æ•°æ®ã€æ­¥éª¤ã€æ³¨æ„äº‹é¡¹ç­‰ã€‚è¦å°½å¯èƒ½å…¨é¢ï¼Œè®©è¯»è€…æ— éœ€çœ‹è§†é¢‘å°±èƒ½äº†è§£è¿™æ®µå†…å®¹çš„æ ¸å¿ƒçŸ¥è¯†ã€‚"
    }},
    {{
      "time": "04:28",
      "title": "ä¸‹ä¸€ä¸ªè¦ç‚¹æ ‡é¢˜",
      "description": "ç»§ç»­è¯¦ç»†æè¿°..."
    }}
  ]
}}
```

å­—å¹•å†…å®¹ï¼š
{subtitle_text}

è¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼çš„æ€»ç»“ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚æ¯ä¸ªè¦ç‚¹çš„descriptionè¦å……åˆ†è¯¦ç»†ï¼Œæ¶µç›–è¯¥æ—¶é—´æ®µçš„å®Œæ•´å†…å®¹ã€‚"""
        
        return prompt
    
    def summarize(self, subtitle_text: str, stream: bool = False) -> Dict:
        """
        æ€»ç»“å­—å¹•å†…å®¹
        
        Args:
            subtitle_text: å­—å¹•æ–‡æœ¬
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            æ€»ç»“ç»“æœ
        """
        prompt = self.create_summary_prompt(subtitle_text)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–è§†é¢‘å…³é”®ä¿¡æ¯å¹¶è¿›è¡Œç»“æ„åŒ–æ€»ç»“ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        if stream:
            print("æ­£åœ¨ç”Ÿæˆæ€»ç»“ï¼ˆæµå¼è¾“å‡ºï¼‰...\n")
            full_response = ""
            for chunk in self.llm_client.chat_completions_stream(messages):
                print(chunk, end='', flush=True)
                full_response += chunk
            print("\n")
            return self._parse_response(full_response)
        else:
            print("æ­£åœ¨ç”Ÿæˆæ€»ç»“...\n")
            response = self.llm_client.chat_completions(messages)
            content = response['choices'][0]['message']['content']
            return self._parse_response(content)
    
    def _parse_response(self, response_text: str) -> Dict:
        """
        è§£æLLMå“åº”
        
        Args:
            response_text: LLMè¿”å›çš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„JSONå¯¹è±¡
        """
        # å°è¯•æå–JSONéƒ¨åˆ†
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
            json_text = response_text.strip()
        
        try:
            result = json.loads(json_text)
            # ç¡®ä¿åªä¿ç•™ key_points å­—æ®µ
            if 'key_points' in result:
                return {'key_points': result['key_points']}
            return result
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è§£æJSONå“åº”: {e}")
            print(f"åŸå§‹å“åº”ï¼š\n{response_text}\n")
            return {
                "key_points": [],
                "raw_response": response_text
            }


def load_llm_config(config_file: str = 'config/llm_models.json', 
                    model_index: int = None, 
                    model_name: str = None) -> Dict:
    """
    åŠ è½½LLMé…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        model_index: ä½¿ç”¨ç¬¬å‡ ä¸ªæ¨¡å‹ï¼ˆç´¢å¼•ï¼Œä»0å¼€å§‹ï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆçº§é«˜äºmodel_indexï¼‰
        
    Returns:
        æ¨¡å‹é…ç½®å­—å…¸
    """
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    models = config.get('models', [])
    if not models:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
    
    # ä¼˜å…ˆä½¿ç”¨model_name
    if model_name:
        for model in models:
            if model.get('name') == model_name:
                print(f"æ‰¾åˆ°æ¨¡å‹: {model_name}")
                return model
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œåˆ—å‡ºå¯ç”¨æ¨¡å‹
        available_names = [m.get('name', 'æœªå‘½å') for m in models]
        raise ValueError(f"æœªæ‰¾åˆ°åä¸º '{model_name}' çš„æ¨¡å‹ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_names)}")
    
    # ä½¿ç”¨model_index
    if model_index is None:
        model_index = 0
    
    if model_index >= len(models):
        print(f"è­¦å‘Šï¼šæ¨¡å‹ç´¢å¼• {model_index} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹")
        model_index = 0
    
    return models[model_index]


def list_available_models(config_file: str = 'config/llm_models.json') -> None:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        models = config.get('models', [])
        if not models:
            print("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
            return
        
        print(f"\nå¯ç”¨çš„æ¨¡å‹ï¼ˆå…± {len(models)} ä¸ªï¼‰ï¼š")
        print("-" * 60)
        for i, model in enumerate(models):
            name = model.get('name', 'æœªå‘½å')
            model_name = model.get('model_name', 'æœªçŸ¥')
            api_base = model.get('api_base', 'æœªçŸ¥')
            print(f"{i}. åç§°: {name}")
            print(f"   æ¨¡å‹: {model_name}")
            print(f"   API: {api_base}")
            print()
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")


def format_output(summary: Dict) -> str:
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    
    Args:
        summary: æ€»ç»“ç»“æœ
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬
    """
    output_lines = []
    output_lines.append("=" * 80)
    output_lines.append("è§†é¢‘å†…å®¹æ€»ç»“")
    output_lines.append("=" * 80)
    output_lines.append("")
    
    # å…³é”®è¦ç‚¹
    key_points = summary.get('key_points', [])
    output_lines.append(f"ğŸ¯ å…³é”®è¦ç‚¹ï¼ˆå…± {len(key_points)} ä¸ªï¼‰ï¼š")
    output_lines.append("")
    
    for i, point in enumerate(key_points, 1):
        time = point.get('time', 'æœªçŸ¥')
        title = point.get('title', 'æ— æ ‡é¢˜')
        description = point.get('description', 'æ— æè¿°')
        
        output_lines.append(f"{i}. [{time}] {title}")
        output_lines.append("")
        # æè¿°å¯èƒ½å¾ˆé•¿ï¼ŒæŒ‰å¥å­æˆ–æ ‡ç‚¹ç¬¦å·åˆ†æ®µæ˜¾ç¤º
        # æ¯è¡Œæœ€å¤š80å­—ç¬¦ï¼Œè‡ªåŠ¨æ¢è¡Œ
        desc_lines = []
        current_line = "   "
        for char in description:
            current_line += char
            if len(current_line) >= 77:  # ç•™3ä¸ªå­—ç¬¦çš„ç¼©è¿›
                # æ‰¾åˆ°æœ€è¿‘çš„æ ‡ç‚¹ç¬¦å·æˆ–ç©ºæ ¼æ¥æ–­è¡Œ
                break_pos = max(
                    current_line.rfind('ã€‚'),
                    current_line.rfind('ï¼Œ'),
                    current_line.rfind('ã€'),
                    current_line.rfind(' ')
                )
                if break_pos > 3:  # ç¡®ä¿ä¸æ˜¯åœ¨å¼€å¤´
                    desc_lines.append(current_line[:break_pos + 1])
                    current_line = "   " + current_line[break_pos + 1:]
                else:
                    desc_lines.append(current_line)
                    current_line = "   "
        
        if current_line.strip():
            desc_lines.append(current_line)
        
        output_lines.extend(desc_lines)
        output_lines.append("")
    
    output_lines.append("=" * 80)
    
    return '\n'.join(output_lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å­—å¹•æ€»ç»“å·¥å…· - ä½¿ç”¨å¤§æ¨¡å‹åˆ†æå­—å¹•å¹¶ç”Ÿæˆè¦ç‚¹æ€»ç»“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
  python subtitle_summarizer.py --list-models
  
  # åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt
  
  # é€šè¿‡åç§°æŒ‡å®šæ¨¡å‹ï¼ˆæ¨èï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -n aivmz8bq80
  
  # é€šè¿‡ç´¢å¼•æŒ‡å®šæ¨¡å‹ï¼ˆ0=ç¬¬ä¸€ä¸ªï¼Œ1=ç¬¬äºŒä¸ªï¼‰
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -m 1
  
  # ä½¿ç”¨æµå¼è¾“å‡º
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -n aivmz8bq80 --stream
  
  # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
  python subtitle_summarizer.py subtitles/è§†é¢‘_ai-zh.srt -o summary.txt
        """
    )
    
    parser.add_argument('subtitle_file', nargs='?', help='SRTå­—å¹•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--model-index', type=int, default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹ç´¢å¼•ï¼ˆé»˜è®¤ï¼š0ï¼Œå³ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰')
    parser.add_argument('-n', '--model-name', default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆçº§é«˜äº-mï¼‰')
    parser.add_argument('-c', '--config', default='config/llm_models.json',
                       help='LLMé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/llm_models.jsonï¼‰')
    parser.add_argument('-o', '--output', default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šå±å¹•è¾“å‡ºï¼‰')
    parser.add_argument('--stream', action='store_true',
                       help='ä½¿ç”¨æµå¼è¾“å‡º')
    parser.add_argument('--save-json', action='store_true',
                       help='åŒæ—¶ä¿å­˜JSONæ ¼å¼çš„ç»“æœ')
    parser.add_argument('--list-models', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯åˆ—å‡ºæ¨¡å‹
    if args.list_models:
        list_available_models(args.config)
        return
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å­—å¹•æ–‡ä»¶
    if not args.subtitle_file:
        parser.print_help()
        print("\né”™è¯¯ï¼šè¯·æä¾›å­—å¹•æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --list-models æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        return
    
    # æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.subtitle_file):
        print(f"é”™è¯¯ï¼šå­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {args.subtitle_file}")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    try:
        # åŠ è½½LLMé…ç½®
        print(f"åŠ è½½æ¨¡å‹é…ç½®...")
        model_config = load_llm_config(
            args.config, 
            model_index=args.model_index,
            model_name=args.model_name
        )
        print(f"ä½¿ç”¨æ¨¡å‹: {model_config['name']}")
        print(f"APIåœ°å€: {model_config['api_base']}")
        print()
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = OpenAICompatClient(
            api_base=model_config['api_base'],
            api_key=model_config['api_key'],
            default_model=model_config['model_name'],
            request_timeout=300  # æ€»ç»“å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
        )
        
        # è§£æå­—å¹•æ–‡ä»¶
        print(f"è¯»å–å­—å¹•æ–‡ä»¶: {args.subtitle_file}")
        subtitles = SRTParser.parse_srt_file(args.subtitle_file)
        print(f"è§£æåˆ° {len(subtitles)} æ¡å­—å¹•")
        print()
        
        # æ ¼å¼åŒ–å­—å¹•æ–‡æœ¬
        subtitle_text = SRTParser.format_subtitles_for_llm(subtitles)
        
        # åˆ›å»ºæ€»ç»“å™¨å¹¶ç”Ÿæˆæ€»ç»“
        summarizer = SubtitleSummarizer(llm_client)
        summary = summarizer.summarize(subtitle_text, stream=args.stream)
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted_output = format_output(summary)
        
        # è¾“å‡ºåˆ°å±å¹•æˆ–æ–‡ä»¶
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(formatted_output)
            print(f"âœ… æ€»ç»“å·²ä¿å­˜åˆ°: {args.output}")
            
            # å¦‚æœéœ€è¦ä¿å­˜JSON
            if args.save_json:
                json_output = args.output.replace('.txt', '.json')
                with open(json_output, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, ensure_ascii=False, indent=2)
                print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_output}")
        else:
            print(formatted_output)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ä½†è¦ä¿å­˜JSON
        if not args.output and args.save_json:
            subtitle_path = Path(args.subtitle_file)
            json_output = subtitle_path.with_suffix('.summary.json')
            with open(json_output, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_output}")
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

