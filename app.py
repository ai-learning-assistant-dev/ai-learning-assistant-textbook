#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bilibiliè§†é¢‘å­—å¹•ä¸‹è½½ä¸æ€»ç»“ - WebæœåŠ¡
"""

import os
import sys
import json
import uuid
import time
import threading
import shutil
from pathlib import Path
from datetime import datetime
from queue import Queue
from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename

from process_generated_content import save_data_to_excel
from bilibili_subtitle_downloader import BilibiliSubtitleDownloader, load_cookies_from_file
from process_video_info import sanitize_filename
from subtitle_summarizer import SRTParser, SubtitleSummarizer, load_llm_config
from llm_client import OpenAICompatClient

# ç¡®å®šæ¨¡æ¿ç›®å½•
if getattr(sys, 'frozen', False):
    # å¦‚æœæ˜¯PyInstalleræ‰“åŒ…ç¯å¢ƒ
    template_folder = os.path.join(sys._MEIPASS, 'templates')
    static_folder = os.path.join(sys._MEIPASS, 'static')
    app = Flask(__name__, template_folder=template_folder, static_folder=static_folder)
else:
    app = Flask(__name__)

app.config['JSON_AS_ASCII'] = False  # æ”¯æŒä¸­æ–‡JSON

# å…¨å±€å˜é‡å­˜å‚¨ä»»åŠ¡çŠ¶æ€
tasks = {}
tasks_lock = threading.Lock()

# ä»»åŠ¡é˜Ÿåˆ—ï¼šç”¨äºé™åˆ¶å¹¶å‘æ•°é‡
task_queue = Queue()
# æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆå¯ä»¥æ ¹æ®APIé™åˆ¶è°ƒæ•´ï¼‰
MAX_CONCURRENT_TASKS = 2  # é»˜è®¤åŒæ—¶æœ€å¤šå¤„ç†2ä¸ªè§†é¢‘
# å·¥ä½œçº¿ç¨‹å¯åŠ¨æ ‡å¿—
worker_threads_started = False
worker_threads_lock = threading.Lock()


class TaskStatus:
    """ä»»åŠ¡çŠ¶æ€ç±»"""
    PENDING = "pending"
    DOWNLOADING = "downloading"
    SUMMARIZING = "summarizing"
    COMPLETED = "completed"
    FAILED = "failed"
    STOPPING = "stopping"  # æ­£åœ¨åœæ­¢ä¸­
    STOPPED = "stopped"    # å·²åœæ­¢


def load_models():
    """åŠ è½½æ¨¡å‹é…ç½®"""
    config_file = 'config/llm_models.json'
    if not os.path.exists(config_file):
        return []
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
        return config.get('models', [])


def save_models(models):
    """ä¿å­˜æ¨¡å‹é…ç½®"""
    config_file = 'config/llm_models.json'
    os.makedirs(os.path.dirname(config_file), exist_ok=True)
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump({'models': models}, f, ensure_ascii=False, indent=2)


def load_app_config():
    """åŠ è½½åº”ç”¨é…ç½®"""
    config_file = 'config/app_config.json'
    
    # é»˜è®¤é…ç½®
    default_config = {
        'output_directory': 'subtitles',
        'last_selected_model': '',
        'cookies_file': 'cookies.txt',
        'auto_refresh_interval': 2000,
        'web_port': 5000,
        'download_all_parts': False,  # é»˜è®¤å…³é—­ï¼šåªä¸‹è½½URLæŒ‡å®šçš„è§†é¢‘ï¼Œä¸ä¸‹è½½æ‰€æœ‰åˆ†P
        'max_concurrent_tasks': 2  # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼šé»˜è®¤åŒæ—¶å¤„ç†2ä¸ªè§†é¢‘ï¼ˆé¿å…APIå¹¶å‘è¿‡é«˜ï¼‰
    }
    
    if not os.path.exists(config_file):
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
        save_app_config(default_config)
        return default_config
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
            # åˆå¹¶é»˜è®¤é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
            for key, value in default_config.items():
                if key not in config:
                    config[key] = value
            return config
    except Exception as e:
        print(f"åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config


def save_app_config(config):
    """ä¿å­˜åº”ç”¨é…ç½®"""
    config_file = 'config/app_config.json'
    os.makedirs(os.path.dirname(config_file), exist_ok=True)
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)


def load_workspaces():
    """åŠ è½½å·¥ä½œåŒºé…ç½®"""
    config_file = 'config/workspace.json'
    if not os.path.exists(config_file):
        return []
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('workspaces', [])
    except Exception as e:
        print(f"åŠ è½½å·¥ä½œåŒºé…ç½®å¤±è´¥: {e}")
        return []


def save_workspaces(workspaces):
    """ä¿å­˜å·¥ä½œåŒºé…ç½®"""
    config_file = 'config/workspace.json'
    os.makedirs(os.path.dirname(config_file), exist_ok=True)
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump({'workspaces': workspaces}, f, ensure_ascii=False, indent=2)


def start_worker_threads():
    """å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± ï¼ˆç¡®ä¿åªå¯åŠ¨ä¸€æ¬¡ï¼‰"""
    global worker_threads_started
    
    with worker_threads_lock:
        if worker_threads_started:
            return
        
        # åŠ è½½é…ç½®è·å–å¹¶å‘æ•°
        config = load_app_config()
        max_concurrent = config.get('max_concurrent_tasks', MAX_CONCURRENT_TASKS)
        
        print(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {max_concurrent} ä¸ªå·¥ä½œçº¿ç¨‹...")
        for i in range(max_concurrent):
            worker = threading.Thread(target=task_queue_worker, daemon=True, name=f"Worker-{i+1}")
            worker.start()
        
        worker_threads_started = True
        print(f"âœ… å·¥ä½œçº¿ç¨‹æ± å·²å¯åŠ¨ï¼ˆ{max_concurrent} ä¸ªçº¿ç¨‹ï¼‰")


def task_queue_worker():
    """ä»»åŠ¡é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹ï¼šä»é˜Ÿåˆ—ä¸­å–ä»»åŠ¡å¹¶æ‰§è¡Œ"""
    thread_name = threading.current_thread().name
    print(f"[{thread_name}] å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾…ä»»åŠ¡...")
    
    while True:
        try:
            # ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡
            task_data = task_queue.get()
            if task_data is None:  # None æ˜¯åœæ­¢ä¿¡å·
                print(f"[{thread_name}] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡º")
                break
            
            task_id = task_data['task_id']
            url = task_data['url']
            output_dir = task_data['output_dir']
            model_name = task_data['model_name']
            cookies_file = task_data['cookies_file']
            custom_folder_name = task_data.get('custom_folder_name')
            download_all_parts = task_data.get('download_all_parts', False)
            generate_options = task_data.get('generate_options')
            
            print(f"[{thread_name}] å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}: {url}")
            
            # æ‰§è¡Œä»»åŠ¡
            process_video_task(task_id, thread_name, url, output_dir, model_name, cookies_file, custom_folder_name, download_all_parts, generate_options)
            
            print(f"[{thread_name}] ä»»åŠ¡ {task_id} å¤„ç†å®Œæˆ")
            
            # ä»»åŠ¡å®Œæˆåç­‰å¾…ä¸€å°æ®µæ—¶é—´å†å¤„ç†ä¸‹ä¸€ä¸ªï¼ˆé¿å…è§¦å‘åçˆ¬è™«ï¼‰
            time.sleep(2)
            
        except Exception as e:
            print(f"[{thread_name}] ä»»åŠ¡é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            task_queue.task_done()


def process_video_task(task_id, thread_name, url, output_dir, model_name, cookies_file, custom_folder_name=None, download_all_parts=False, generate_options=None):
    """å¤„ç†å•ä¸ªè§†é¢‘çš„ä¸‹è½½å’Œæ€»ç»“ä»»åŠ¡"""
    if generate_options is None:
        generate_options = {
            'summary': True,
            'full_content': True,
            'exercises': True,
            'questions': True
        }
    try:
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        with tasks_lock:
            if tasks[task_id].get('stop_flag'):
                tasks[task_id]['status'] = TaskStatus.STOPPED
                tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                return
        
        # æ›´æ–°çŠ¶æ€ï¼šä¸‹è½½ä¸­
        with tasks_lock:
            tasks[task_id]['status'] = TaskStatus.DOWNLOADING
            tasks[task_id]['message'] = f'æ­£åœ¨ä¸‹è½½å­—å¹•: {url}'
        
        # åŠ è½½Cookie
        config_cookies = load_cookies_from_file(cookies_file)
        sessdata = config_cookies.get('sessdata')
        
        # åˆ›å»ºä¸‹è½½å™¨
        downloader = BilibiliSubtitleDownloader(
            sessdata=sessdata,
            bili_jct=config_cookies.get('bili_jct'),
            buvid3=config_cookies.get('buvid3'),
            debug=False
        )
        
        # ä¸‹è½½å­—å¹•å’Œå°é¢
        download_result = downloader.download(
            video_url=url,
            video_index=thread_name,
            output_dir=output_dir,
            format_type='srt',
            download_cover=True,
            custom_folder_name=custom_folder_name,
            download_all_parts=download_all_parts
        )
        
        # è·å–ä¸‹è½½ç»“æœ
        downloaded_files = download_result.get('subtitles', [])
        cover_path = download_result.get('cover')
        video_title = download_result.get('title', '')
        video_dir = download_result.get('video_dir', output_dir)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸä¸‹è½½äº†å­—å¹•
        if not downloaded_files:
            raise Exception('æ­¤è§†é¢‘æ²¡æœ‰å­—å¹•ï¼Œæ— æ³•è¿›è¡Œæ€»ç»“')
        
        # æ£€æŸ¥åœæ­¢æ ‡å¿—
        with tasks_lock:
            if tasks[task_id].get('stop_flag'):
                tasks[task_id]['status'] = TaskStatus.STOPPED
                tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                return
        
        # æ›´æ–°ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
        with tasks_lock:
            tasks[task_id]['video_dir'] = video_dir
            tasks[task_id]['video_title'] = video_title
        
        # åŠ è½½LLMé…ç½®
        llm_config_file = 'config/llm_models.json'
        model_config = load_llm_config(llm_config_file, model_name=model_name)
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = OpenAICompatClient(
            api_base=model_config['api_base'],
            api_key=model_config['api_key'],
            default_model=model_config['model_name'],
            request_timeout=500
        )
        
        # åˆ›å»ºæ€»ç»“å™¨
        summarizer = SubtitleSummarizer(llm_client)
        
        # å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
        all_generated_files = []
        
        # éå†æ‰€æœ‰ä¸‹è½½çš„ä¸­æ–‡å­—å¹•æ–‡ä»¶
        total_files = len(downloaded_files)
        for file_index, subtitle_file in enumerate(downloaded_files, 1):
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            with tasks_lock:
                if tasks[task_id].get('stop_flag'):
                    tasks[task_id]['status'] = TaskStatus.STOPPED
                    tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                    return
            
            # ä»å­—å¹•æ–‡ä»¶åä¸­æå–æ ‡é¢˜
            subtitle_filename = os.path.basename(subtitle_file)
            subtitle_name = os.path.splitext(subtitle_filename)[0]
            subtitle_title = subtitle_name.rsplit('_', 1)[0] if '_' in subtitle_name else subtitle_name
            
            # å®šä¹‰æ‰€æœ‰å¯èƒ½ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
            summary_json_file = os.path.join(video_dir, f'{subtitle_title}_summary.json')
            # markdown_dir = os.path.join(video_dir, 'markdown')
            # full_content_file = os.path.join(markdown_dir, f'{subtitle_title}.md')
            # æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼ŒMarkdownæ–‡ä»¶åº”ç›´æ¥å­˜æ”¾åœ¨video_dirä¸‹
            full_content_file = os.path.join(video_dir, f'{subtitle_title}.md')
            exercises_file = os.path.join(video_dir, f'{subtitle_title}_exercises.json')
            questions_file = os.path.join(video_dir, f'{subtitle_title}_questions.json')
            
            # è§£æå­—å¹•ï¼ˆæå‰è§£æï¼Œä¾›åç»­æ­¥éª¤ä½¿ç”¨ï¼‰
            subtitles = None
            subtitle_text = None
            plain_text = None
            
            # ========== 1. ç”Ÿæˆè¦ç‚¹æ€»ç»“ ==========
            if generate_options.get('summary', True):
                if os.path.exists(summary_json_file):
                    with tasks_lock:
                        tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (1/4): è¦ç‚¹æ€»ç»“å·²å­˜åœ¨ï¼Œè·³è¿‡'
                else:
                    with tasks_lock:
                        tasks[task_id]['status'] = TaskStatus.SUMMARIZING
                        tasks[task_id]['message'] = f'æ­£åœ¨å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (1/4): è¦ç‚¹æ€»ç»“...'
                        tasks[task_id]['subtitle_file'] = subtitle_file
                    
                    # è§£æå­—å¹•
                    if subtitles is None:
                        subtitles = SRTParser.parse_srt_file(subtitle_file)
                        subtitle_text = SRTParser.format_subtitles_for_llm(subtitles)
                    
                    summary = summarizer.summarize(subtitle_text, stream=False)
                    
                    with open(summary_json_file, 'w', encoding='utf-8') as f:
                        json.dump(summary, f, ensure_ascii=False, indent=2)
            else:
                with tasks_lock:
                     tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (1/4): è¦ç‚¹æ€»ç»“ (ç”¨æˆ·é€‰æ‹©è·³è¿‡)'
            
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            with tasks_lock:
                if tasks[task_id].get('stop_flag'):
                    tasks[task_id]['status'] = TaskStatus.STOPPED
                    tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                    return
            
            # ========== 2. ç”Ÿæˆå®Œæ•´å†…å®¹æ–‡æ¡£ ==========
            if generate_options.get('full_content', True):
                if os.path.exists(full_content_file):
                    with tasks_lock:
                        tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (2/4): å®Œæ•´æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡'
                else:
                    with tasks_lock:
                        tasks[task_id]['message'] = f'æ­£åœ¨å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (2/4): å®Œæ•´æ–‡æ¡£...'
                    
                    # é¢„å¤„ç†å­—å¹•æ–‡æœ¬
                    if plain_text is None:
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    full_content = summarizer.generate_full_content(
                        plain_text,
                        video_title=video_title,
                        stream=False
                    )
                    
                    # åˆ›å»ºmarkdownå­ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    # os.makedirs(markdown_dir, exist_ok=True)
                    
                    with open(full_content_file, 'w', encoding='utf-8') as f:
                        f.write(full_content)
            else:
                with tasks_lock:
                     tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (2/4): å®Œæ•´æ–‡æ¡£ (ç”¨æˆ·é€‰æ‹©è·³è¿‡)'
            
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            with tasks_lock:
                if tasks[task_id].get('stop_flag'):
                    tasks[task_id]['status'] = TaskStatus.STOPPED
                    tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                    return
            
            # ========== 3. ç”Ÿæˆç»ƒä¹ é¢˜ ==========
            if generate_options.get('exercises', True):
                if os.path.exists(exercises_file):
                    with tasks_lock:
                        tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (3/4): ç»ƒä¹ é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡'
                else:
                    with tasks_lock:
                        tasks[task_id]['message'] = f'æ­£åœ¨å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (3/4): ç»ƒä¹ é¢˜...'
                    
                    # é¢„å¤„ç†å­—å¹•æ–‡æœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if plain_text is None:
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    exercises = summarizer.generate_exercises(
                        plain_text,
                        video_title=video_title,
                        stream=False
                    )
                    
                    with open(exercises_file, 'w', encoding='utf-8') as f:
                        json.dump(exercises, f, ensure_ascii=False, indent=2)
            else:
                with tasks_lock:
                     tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (3/4): ç»ƒä¹ é¢˜ (ç”¨æˆ·é€‰æ‹©è·³è¿‡)'
            
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            with tasks_lock:
                if tasks[task_id].get('stop_flag'):
                    tasks[task_id]['status'] = TaskStatus.STOPPED
                    tasks[task_id]['message'] = 'ä»»åŠ¡å·²åœæ­¢'
                    return
            
            # ========== 4. ç”Ÿæˆé¢„è®¾é—®é¢˜ ==========
            if generate_options.get('questions', True):
                if os.path.exists(questions_file):
                    with tasks_lock:
                        tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (4/4): é¢„è®¾é—®é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡'
                else:
                    with tasks_lock:
                        tasks[task_id]['message'] = f'æ­£åœ¨å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (4/4): é¢„è®¾é—®é¢˜...'
                    
                    # é¢„å¤„ç†å­—å¹•æ–‡æœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if plain_text is None:
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    preset_questions = summarizer.generate_preset_questions(
                        plain_text,
                        video_title=video_title,
                        stream=False
                    )
                    
                    with open(questions_file, 'w', encoding='utf-8') as f:
                        json.dump(preset_questions, f, ensure_ascii=False, indent=2)
            else:
                with tasks_lock:
                     tasks[task_id]['message'] = f'å¤„ç†å­—å¹• {file_index}/{total_files}: {subtitle_title} (4/4): é¢„è®¾é—®é¢˜ (ç”¨æˆ·é€‰æ‹©è·³è¿‡)'
            
            # è®°å½•æœ¬å­—å¹•ç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶
            all_generated_files.append({
                'subtitle_title': subtitle_title,
                'subtitle_file': subtitle_file,
                'summary_json': summary_json_file,
                'content_md': full_content_file,
                'exercises': exercises_file,
                'questions': questions_file
            })
        # 5. å°†ç”Ÿæˆçš„æ•°æ®å†™å…¥ Excel
        with tasks_lock:
            tasks[task_id]['message'] = f'æ­£åœ¨å†™å…¥Excel: {video_title}...'
        
        # video_dir æŒ‡å‘ .../data ç›®å½•ï¼ŒExcel æ–‡ä»¶å®é™…ä¸Šåœ¨ä¸Šä¸€çº§ç›®å½•
        # æ­£ç¡®çš„é€»è¾‘åº”è¯¥æ˜¯å»æ‰¾çˆ¶ç›®å½•ä¸‹çš„ .xlsx æ–‡ä»¶
        parent_dir = os.path.dirname(video_dir)
        # å°è¯•å‡ ç§å¯èƒ½çš„å‘½åæ–¹å¼
        possible_names = [
            f"{os.path.basename(parent_dir)}.xlsx",
            f"{sanitize_filename(video_title)}.xlsx"
        ]
        
        excel_found = False
        for name in possible_names:
            excel_path = os.path.join(parent_dir, name)
            if os.path.exists(excel_path):
                save_data_to_excel(excel_path)
                excel_found = True
                break
        
        if not excel_found:
            print(f"è­¦å‘Š: Excel æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°è¯•äº†: {possible_names}")
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨ video_dir (å³ data ç›®å½•) ä¸‹æ‰¾æ‰¾çœ‹ï¼Œè™½ç„¶è¿™ä¸åº”è¯¥å‘ç”Ÿ
            excel_path_fallback = os.path.join(video_dir, f"{os.path.basename(video_dir)}.xlsx")
            if os.path.exists(excel_path_fallback):
                 save_data_to_excel(excel_path_fallback)
            else:
                 with tasks_lock:
                     tasks[task_id]['message'] += ' (Excelå†™å…¥å¤±è´¥: æ–‡ä»¶æœªæ‰¾åˆ°)'

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
        with tasks_lock:
            tasks[task_id]['status'] = TaskStatus.COMPLETED
            tasks[task_id]['message'] = f'å…¨éƒ¨å®Œæˆï¼å·²å¤„ç† {total_files} ä¸ªå­—å¹•æ–‡ä»¶ï¼Œç”Ÿæˆäº†å­—å¹•ã€å°é¢ã€æ€»ç»“ã€å®Œæ•´æ–‡æ¡£ã€ç»ƒä¹ é¢˜å’Œé¢„è®¾é—®é¢˜'
            tasks[task_id]['files'] = {
                'video_dir': video_dir,
                'cover': cover_path,
                'generated_files': all_generated_files
            }
            tasks[task_id]['completed_at'] = datetime.now().isoformat()
        
    except Exception as e:
        # æ›´æ–°çŠ¶æ€ï¼šå¤±è´¥
        with tasks_lock:
            tasks[task_id]['status'] = TaskStatus.FAILED
            tasks[task_id]['message'] = f'é”™è¯¯: {str(e)}'
            tasks[task_id]['error'] = str(e)




# ==================== Webè·¯ç”± ====================

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/api/models', methods=['GET'])
def get_models():
    """è·å–æ¨¡å‹åˆ—è¡¨"""
    try:
        models = load_models()
        return jsonify({
            'success': True,
            'models': models
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/models', methods=['POST'])
def add_model():
    """æ·»åŠ æ¨¡å‹"""
    try:
        data = request.json
        
        # ç”Ÿæˆå”¯ä¸€ID
        model_id = datetime.now().strftime('%Y%m%d%H%M%S%f')
        
        new_model = {
            'id': model_id,
            'name': data.get('name'),
            'model_name': data.get('model_name'),
            'api_base': data.get('api_base'),
            'api_key': data.get('api_key')
        }
        
        models = load_models()
        models.append(new_model)
        save_models(models)
        
        return jsonify({
            'success': True,
            'model': new_model
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/models/<model_id>', methods=['PUT'])
def update_model(model_id):
    """æ›´æ–°æ¨¡å‹"""
    try:
        data = request.json
        models = load_models()
        
        for model in models:
            if model['id'] == model_id:
                model['name'] = data.get('name', model['name'])
                model['model_name'] = data.get('model_name', model['model_name'])
                model['api_base'] = data.get('api_base', model['api_base'])
                model['api_key'] = data.get('api_key', model['api_key'])
                break
        
        save_models(models)
        
        return jsonify({
            'success': True
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/models/<model_id>', methods=['DELETE'])
def delete_model(model_id):
    """åˆ é™¤æ¨¡å‹"""
    try:
        models = load_models()
        models = [m for m in models if m['id'] != model_id]
        save_models(models)
        
        return jsonify({
            'success': True
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/workspace', methods=['POST'])
def create_workspace():
    """åˆ›å»ºå·¥ä½œåŒº"""
    try:
        data = request.json
        name = data.get('name', '').strip()
        path = data.get('path', '').strip()
        
        if not name:
            return jsonify({
                'success': False,
                'error': 'å·¥ä½œåŒºåç§°ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if not path:
            return jsonify({
                'success': False,
                'error': 'å·¥ä½œåŒºè·¯å¾„ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # åŠ è½½ç°æœ‰å·¥ä½œåŒº
        workspaces = load_workspaces()
        
        # æ£€æŸ¥åç§°æ˜¯å¦é‡å¤
        for ws in workspaces:
            if ws.get('name') == name:
                return jsonify({
                    'success': False,
                    'error': f'å·¥ä½œåŒºåç§° "{name}" å·²å­˜åœ¨'
                }), 400
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.abspath(path)
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(full_path):
            return jsonify({
                'success': False,
                'error': f'è·¯å¾„ "{path}" å·²å­˜åœ¨'
            }), 400
        
        # åˆ›å»ºæ–‡ä»¶å¤¹
        try:
            os.makedirs(full_path, exist_ok=False)
        except OSError as e:
            return jsonify({
                'success': False,
                'error': f'åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {str(e)}'
            }), 500
        
        # æ·»åŠ æ–°å·¥ä½œåŒº
        new_workspace = {
            'name': name,
            'path': path,
            'created_at': datetime.now().isoformat()
        }
        workspaces.append(new_workspace)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        save_workspaces(workspaces)
        
        return jsonify({
            'success': True,
            'workspace': new_workspace,
            'full_path': full_path
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/workspace', methods=['GET'])
def list_workspaces():
    """è·å–æ‰€æœ‰å·¥ä½œåŒºåˆ—è¡¨"""
    try:
        workspaces = load_workspaces()
        return jsonify({
            'success': True,
            'workspaces': workspaces
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/workspace/<workspace_name>', methods=['DELETE'])
def delete_workspace(workspace_name):
    """åˆ é™¤å·¥ä½œåŒº"""
    try:
        # åŠ è½½ç°æœ‰å·¥ä½œåŒº
        workspaces = load_workspaces()
        
        # æŸ¥æ‰¾è¦åˆ é™¤çš„å·¥ä½œåŒº
        target_workspace = None
        for ws in workspaces:
            if ws.get('name') == workspace_name:
                target_workspace = ws
                break
        
        if not target_workspace:
            return jsonify({
                'success': False,
                'error': f'å·¥ä½œåŒº "{workspace_name}" ä¸å­˜åœ¨'
            }), 404
        
        # è·å–å·¥ä½œåŒºè·¯å¾„
        workspace_path = target_workspace.get('path')
        full_path = os.path.abspath(workspace_path)
        
        # åˆ é™¤æ–‡ä»¶å¤¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(full_path):
            try:
                shutil.rmtree(full_path)
            except OSError as e:
                return jsonify({
                    'success': False,
                    'error': f'åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}'
                }), 500
        
        # ä»åˆ—è¡¨ä¸­åˆ é™¤å·¥ä½œåŒº
        workspaces = [ws for ws in workspaces if ws.get('name') != workspace_name]
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        save_workspaces(workspaces)
        
        return jsonify({
            'success': True,
            'message': f'å·¥ä½œåŒº "{workspace_name}" å·²åˆ é™¤',
            'deleted_path': full_path
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/tasks', methods=['POST'])
def create_tasks():
    """åˆ›å»ºæ‰¹é‡ä»»åŠ¡"""
    try:
        # ç¡®ä¿å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨
        start_worker_threads()
        
        data = request.json
        urls = data.get('urls', [])
        output_dir = data.get('output_dir', 'subtitles')
        model_name = data.get('model_name')
        cookies_file = data.get('cookies_file', 'cookies.txt')
        custom_folder_name = data.get('custom_folder_name', '').strip() or None
        download_all_parts = data.get('download_all_parts', False)
        generate_options = data.get('generate_options', {
            'summary': True,
            'full_content': True,
            'exercises': True,
            'questions': True
        })
        
        if not urls:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›è‡³å°‘ä¸€ä¸ªURL'
            }), 400
        
        if not model_name:
            return jsonify({
                'success': False,
                'error': 'è¯·é€‰æ‹©æ¨¡å‹'
            }), 400
        
        # ä¿å­˜é…ç½®ï¼šæœ€åä½¿ç”¨çš„è¾“å‡ºç›®å½•å’Œæ¨¡å‹
        config = load_app_config()
        config['output_directory'] = output_dir
        config['last_selected_model'] = model_name
        save_app_config(config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½Cookieç”¨äºæ£€æµ‹æ”¶è—å¤¹
        config_cookies = load_cookies_from_file(cookies_file)
        
        # å¤„ç†URLåˆ—è¡¨ï¼Œå±•å¼€æ”¶è—å¤¹URL
        expanded_urls = []
        for url in urls:
            url = url.strip()
            if not url:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¶è—å¤¹URL
            downloader = BilibiliSubtitleDownloader(
                sessdata=config_cookies.get('sessdata'),
                bili_jct=config_cookies.get('bili_jct'),
                buvid3=config_cookies.get('buvid3'),
                debug=False
            )
            
            if downloader.is_favorite_url(url):
                # è·å–æ”¶è—å¤¹ID
                fid = downloader.extract_fid(url)
                if fid:
                    print(f"æ£€æµ‹åˆ°æ”¶è—å¤¹URLï¼Œæ­£åœ¨è·å–è§†é¢‘åˆ—è¡¨...")
                    # è·å–æ”¶è—å¤¹å†…çš„è§†é¢‘åˆ—è¡¨
                    videos = downloader.get_favorite_videos(fid)
                    for video in videos:
                        video_url = f"https://www.bilibili.com/video/{video['bvid']}"
                        expanded_urls.append(video_url)
                    print(f"æ”¶è—å¤¹å±•å¼€å®Œæˆï¼Œå…± {len(videos)} ä¸ªè§†é¢‘")
                else:
                    # æ— æ³•æå–æ”¶è—å¤¹IDï¼Œå½“ä½œæ™®é€šè§†é¢‘URLå¤„ç†
                    print(f"æ— æ³•ä»æ”¶è—å¤¹URLä¸­æå–IDï¼Œå°†ä½œä¸ºæ™®é€šè§†é¢‘å¤„ç†: {url}")
                    expanded_urls.append(url)
            else:
                # æ™®é€šè§†é¢‘URL
                expanded_urls.append(url)
        
        if not expanded_urls:
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘URL'
            }), 400
        
        # åˆ›å»ºä»»åŠ¡å¹¶åŠ å…¥é˜Ÿåˆ—
        task_ids = []
        for index, url in enumerate(expanded_urls):
            task_id = str(uuid.uuid4())
            
            with tasks_lock:
                tasks[task_id] = {
                    'id': task_id,
                    'url': url,
                    'status': TaskStatus.PENDING,
                    'message': 'ç­‰å¾…é˜Ÿåˆ—å¤„ç†ï¼ˆé¿å…å¹¶å‘è¿‡é«˜ï¼‰',
                    'created_at': datetime.now().isoformat()
                }
            
            # å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—ï¼Œè€Œä¸æ˜¯ç›´æ¥å¯åŠ¨çº¿ç¨‹
            task_data = {
                'task_id': task_id,
                'url': url,
                'output_dir': output_dir,
                'model_name': model_name,
                'cookies_file': cookies_file,
                'custom_folder_name': custom_folder_name,
                'download_all_parts': download_all_parts,
                'generate_options': generate_options
            }
            task_queue.put(task_data)
            
            task_ids.append(task_id)
        
        # è·å–å½“å‰é…ç½®çš„å¹¶å‘æ•°
        config = load_app_config()
        max_concurrent = config.get('max_concurrent_tasks', MAX_CONCURRENT_TASKS)
        
        return jsonify({
            'success': True,
            'task_ids': task_ids,
            'total_videos': len(expanded_urls),
            'message': f'å·²åˆ›å»º {len(task_ids)} ä¸ªä»»åŠ¡ï¼Œæœ€å¤šåŒæ—¶å¤„ç† {max_concurrent} ä¸ªè§†é¢‘'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/tasks/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    with tasks_lock:
        task = tasks.get(task_id)
        if not task:
            return jsonify({
                'success': False,
                'error': 'ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404
        
        return jsonify({
            'success': True,
            'task': task
        })


@app.route('/api/tasks', methods=['GET'])
def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡"""
    with tasks_lock:
        return jsonify({
            'success': True,
            'tasks': list(tasks.values())
        })


@app.route('/api/tasks/<task_id>/stop', methods=['POST'])
def stop_task(task_id):
    """åœæ­¢ä»»åŠ¡"""
    try:
        with tasks_lock:
            task = tasks.get(task_id)
            if not task:
                return jsonify({
                    'success': False,
                    'error': 'ä»»åŠ¡ä¸å­˜åœ¨'
                }), 404
            
            # å¦‚æœä»»åŠ¡å·²ç»å®Œæˆã€å¤±è´¥æˆ–åœæ­¢ï¼Œåˆ™ä¸èƒ½å†åœæ­¢
            if task['status'] in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.STOPPED]:
                return jsonify({
                    'success': False,
                    'error': f'ä»»åŠ¡å·²ç»æ˜¯{task["status"]}çŠ¶æ€ï¼Œæ— æ³•åœæ­¢'
                }), 400
            
            # è®¾ç½®åœæ­¢æ ‡å¿—å’Œæ›´æ–°çŠ¶æ€
            task['stop_flag'] = True
            task['status'] = TaskStatus.STOPPING
            task['message'] = 'æ­£åœ¨åœæ­¢ä»»åŠ¡ï¼Œè¯·ç­‰å¾…å½“å‰æ­¥éª¤å®Œæˆ...'
        
        return jsonify({
            'success': True,
            'message': 'åœæ­¢ä¿¡å·å·²å‘é€'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/config/cookies', methods=['GET'])
def get_cookies_config():
    """è·å–Cookieé…ç½®"""
    try:
        cookies_file = 'cookies.txt'
        if not os.path.exists(cookies_file):
            return jsonify({
                'success': True,
                'configured': False
            })
        
        cookies = load_cookies_from_file(cookies_file)
        return jsonify({
            'success': True,
            'configured': bool(cookies.get('sessdata'))
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/config', methods=['GET'])
def get_app_config():
    """è·å–åº”ç”¨é…ç½®"""
    try:
        config = load_app_config()
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/config', methods=['POST'])
def update_app_config():
    """æ›´æ–°åº”ç”¨é…ç½®"""
    try:
        data = request.json
        
        # åŠ è½½å½“å‰é…ç½®
        config = load_app_config()
        
        # æ›´æ–°é…ç½®å­—æ®µ
        if 'output_directory' in data:
            config['output_directory'] = data['output_directory']
        if 'last_selected_model' in data:
            config['last_selected_model'] = data['last_selected_model']
        if 'cookies_file' in data:
            config['cookies_file'] = data['cookies_file']
        if 'auto_refresh_interval' in data:
            config['auto_refresh_interval'] = data['auto_refresh_interval']
        if 'web_port' in data:
            config['web_port'] = data['web_port']
        if 'download_all_parts' in data:
            config['download_all_parts'] = data['download_all_parts']
        if 'max_concurrent_tasks' in data:
            config['max_concurrent_tasks'] = data['max_concurrent_tasks']
        
        # ä¿å­˜é…ç½®
        save_app_config(config)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


if __name__ == '__main__':
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    os.makedirs('config', exist_ok=True)
    os.makedirs('subtitles', exist_ok=True)
    os.makedirs('templates', exist_ok=True)
    
    # åŠ è½½é…ç½®è·å–ç«¯å£å’Œå¹¶å‘æ•°
    config = load_app_config()
    port = config.get('web_port', 5000)
    max_concurrent = config.get('max_concurrent_tasks', MAX_CONCURRENT_TASKS)
    
    print("=" * 80)
    print("Bilibiliè§†é¢‘å­—å¹•ä¸‹è½½ä¸æ€»ç»“ - WebæœåŠ¡")
    print("=" * 80)
    print()
    print("æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"è®¿é—®åœ°å€: http://127.0.0.1:{port}")
    print(f"æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°: {max_concurrent}")
    print(f"å·¥ä½œçº¿ç¨‹å°†åœ¨é¦–æ¬¡åˆ›å»ºä»»åŠ¡æ—¶å¯åŠ¨")
    print()
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 80)
    print()
    
    # ä½¿ç”¨ use_reloader=False é¿å…Flaské‡æ–°åŠ è½½å¯¼è‡´å·¥ä½œçº¿ç¨‹ä¸¢å¤±
    # ä½¿ç”¨ debug=False åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ–è€…ç¡®ä¿å·¥ä½œçº¿ç¨‹åœ¨æ¯æ¬¡é‡è½½åéƒ½èƒ½æ­£ç¡®å¯åŠ¨
    app.run(host='0.0.0.0', port=port, debug=True, use_reloader=False, threaded=True)



