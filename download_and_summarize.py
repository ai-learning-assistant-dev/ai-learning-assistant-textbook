#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®ä¸‹è½½å¹¶æ€»ç»“Bilibiliè§†é¢‘å­—å¹•
"""

import os
import sys
import argparse
import json
from pathlib import Path

from bilibili_subtitle_downloader import BilibiliSubtitleDownloader, load_cookies_from_file
from subtitle_summarizer import (
    SRTParser, SubtitleSummarizer, load_llm_config, format_output
)
from llm_client import OpenAICompatClient


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä¸€é”®ä¸‹è½½Bilibiliè§†é¢‘å­—å¹•å¹¶ç”Ÿæˆè¦ç‚¹æ€»ç»“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
  python download_and_summarize.py --list-models
  
  # åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨cookies.txtå’Œé»˜è®¤æ¨¡å‹ï¼‰
  python download_and_summarize.py "https://www.bilibili.com/video/BV1xx411c7mu"
  
  # é€šè¿‡åç§°æŒ‡å®šæ¨¡å‹ï¼ˆæ¨èï¼‰
  python download_and_summarize.py "è§†é¢‘URL" -n aivmz8bq80
  
  # é€šè¿‡ç´¢å¼•æŒ‡å®šæ¨¡å‹
  python download_and_summarize.py "è§†é¢‘URL" -m 1
  
  # ä½¿ç”¨æµå¼è¾“å‡ºæ€»ç»“è¿‡ç¨‹
  python download_and_summarize.py "è§†é¢‘URL" -n aivmz8bq80 --stream
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python download_and_summarize.py "è§†é¢‘URL" -o ./output
  
  # åªä¸‹è½½ä¸æ€»ç»“
  python download_and_summarize.py "è§†é¢‘URL" --download-only
        """
    )
    
    parser.add_argument('url', nargs='?', help='Bilibiliè§†é¢‘URL')
    parser.add_argument('-o', '--output', default='subtitles',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šsubtitlesï¼‰')
    parser.add_argument('-m', '--model-index', type=int, default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹ç´¢å¼•ï¼ˆé»˜è®¤ï¼š0ï¼‰')
    parser.add_argument('-n', '--model-name', default=None,
                       help='ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆçº§é«˜äº-mï¼‰')
    parser.add_argument('--config', default='cookies.txt',
                       help='Cookieé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šcookies.txtï¼‰')
    parser.add_argument('--llm-config', default='config/llm_models.json',
                       help='LLMé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/llm_models.jsonï¼‰')
    parser.add_argument('--stream', action='store_true',
                       help='ä½¿ç”¨æµå¼è¾“å‡ºæ€»ç»“')
    parser.add_argument('--download-only', action='store_true',
                       help='åªä¸‹è½½å­—å¹•ï¼Œä¸è¿›è¡Œæ€»ç»“')
    parser.add_argument('--list-models', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯åˆ—å‡ºæ¨¡å‹
    if args.list_models:
        from subtitle_summarizer import list_available_models
        list_available_models(args.llm_config)
        return
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†URL
    if not args.url:
        parser.print_help()
        print("\né”™è¯¯ï¼šè¯·æä¾›è§†é¢‘URLï¼Œæˆ–ä½¿ç”¨ --list-models æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        sys.exit(1)
    
    print("=" * 80)
    print("Bilibiliè§†é¢‘å­—å¹•ä¸‹è½½ä¸æ€»ç»“å·¥å…·")
    print("=" * 80)
    print()
    
    # ========== ç¬¬ä¸€æ­¥ï¼šä¸‹è½½å­—å¹• ==========
    print("ğŸ¬ ç¬¬ä¸€æ­¥ï¼šä¸‹è½½è§†é¢‘å­—å¹•")
    print("-" * 80)
    
    try:
        # ä»é…ç½®æ–‡ä»¶åŠ è½½Cookie
        config_cookies = load_cookies_from_file(args.config)
        sessdata = config_cookies.get('sessdata')
        
        if not sessdata:
            print("è­¦å‘Šï¼šæœªåœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°SESSDATAï¼Œå¯èƒ½æ— æ³•ä¸‹è½½AIå­—å¹•")
        
        # åˆ›å»ºä¸‹è½½å™¨ï¼ˆå¯ç”¨åçˆ¬è™«ä¿æŠ¤ï¼‰
        downloader = BilibiliSubtitleDownloader(
            sessdata=sessdata,
            bili_jct=config_cookies.get('bili_jct'),
            buvid3=config_cookies.get('buvid3'),
            debug=args.debug,
            request_delay=2.0,  # è¯·æ±‚é—´éš”2ç§’
            max_retries=3       # æœ€å¤šé‡è¯•3æ¬¡
        )
        
        # ä¸‹è½½å­—å¹•å’Œå°é¢
        print(f"è§†é¢‘URL: {args.url}")
        print(f"è¾“å‡ºç›®å½•: {args.output}")
        print()
        
        download_result = downloader.download(
            video_url=args.url,
            output_dir=args.output,
            format_type='srt',
            download_cover=True
        )
        
        downloaded_files = download_result.get('subtitles', [])
        cover_path = download_result.get('cover')
        video_title = download_result.get('title', '')
        video_dir = download_result.get('video_dir', args.output)
        
        print()
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸä¸‹è½½äº†å­—å¹•
        if not downloaded_files:
            print("âŒ æ­¤è§†é¢‘æ²¡æœ‰å­—å¹•ï¼Œæ— æ³•è¿›è¡Œæ€»ç»“")
            sys.exit(0)
        
        print("âœ… å­—å¹•ä¸‹è½½å®Œæˆï¼")
        if cover_path:
            print(f"âœ… å°é¢å›¾ç‰‡å·²ä¿å­˜: {cover_path}")
        print(f"âœ… æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {video_dir}")
        print()
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å­—å¹•æ—¶å‡ºé”™: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    
    # å¦‚æœåªéœ€è¦ä¸‹è½½ï¼Œåˆ™é€€å‡º
    if args.download_only:
        print("å·²å®Œæˆä¸‹è½½ï¼Œè·³è¿‡æ€»ç»“æ­¥éª¤")
        return
    
    # ========== ç¬¬äºŒæ­¥ï¼šAIç”Ÿæˆè¦ç‚¹æ€»ç»“ ==========
    print("ğŸ¤– ç¬¬äºŒæ­¥ï¼šAIç”Ÿæˆè¦ç‚¹æ€»ç»“")
    print("-" * 80)
    
    try:
        # åŠ è½½LLMé…ç½®
        if not os.path.exists(args.llm_config):
            print(f"âŒ é”™è¯¯ï¼šLLMé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.llm_config}")
            sys.exit(1)
        
        model_config = load_llm_config(
            args.llm_config, 
            model_index=args.model_index,
            model_name=args.model_name
        )
        print(f"ä½¿ç”¨æ¨¡å‹: {model_config['name']}")
        print(f"APIåœ°å€: {model_config['api_base']}")
        print()
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = OpenAICompatClient(
            api_base=model_config['api_base'],
            api_key=model_config['api_key'],
            default_model=model_config['model_name'],
            request_timeout=300
        )
        
        # ç»Ÿè®¡
        total_files = len(downloaded_files)
        success_count = 0
        failed_count = 0
        
        # éå†æ‰€æœ‰ä¸‹è½½çš„å­—å¹•æ–‡ä»¶ï¼Œå¯¹æ¯ä¸ªéƒ½è¿›è¡Œæ€»ç»“
        for index, subtitle_file in enumerate(downloaded_files, 1):
            print()
            print("=" * 80)
            if total_files > 1:
                print(f"ğŸ“„ æ­£åœ¨å¤„ç†ç¬¬ {index}/{total_files} ä¸ªå­—å¹•æ–‡ä»¶")
            print(f"æ–‡ä»¶: {subtitle_file}")
            print("-" * 80)
            
            try:
                # ä»å­—å¹•æ–‡ä»¶åä¸­æå–æ ‡é¢˜ï¼ˆå»é™¤æ‰©å±•åå’Œè¯­è¨€åç¼€ï¼‰
                subtitle_filename = os.path.basename(subtitle_file)
                # å»é™¤æ‰©å±•å
                subtitle_name = os.path.splitext(subtitle_filename)[0]
                # å»é™¤è¯­è¨€åç¼€ï¼ˆå¦‚ _ai-zh, _zh-CN ç­‰ï¼‰
                subtitle_title = subtitle_name.rsplit('_', 1)[0] if '_' in subtitle_name else subtitle_name
                
                if args.debug:
                    print(f"[DEBUG] å­—å¹•æ ‡é¢˜: {subtitle_title}")
                
                # å®šä¹‰æ‰€æœ‰å¯èƒ½ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
                summary_json_file = os.path.join(video_dir, f'{subtitle_title}_summary.json')
                markdown_dir = os.path.join(video_dir, 'markdown')
                full_content_file = os.path.join(markdown_dir, f'{subtitle_title}.md')
                exercises_file = os.path.join(video_dir, f'{subtitle_title}_exercises.json')
                questions_file = os.path.join(video_dir, f'{subtitle_title}_questions.json')
                
                # è§£æå­—å¹•ï¼ˆæå‰è§£æï¼Œä¾›åç»­æ­¥éª¤ä½¿ç”¨ï¼‰
                subtitles = None
                subtitle_text = None
                plain_text = None
                summarizer = SubtitleSummarizer(llm_client)
                
                # ========== 1. ç”Ÿæˆè¦ç‚¹æ€»ç»“ ==========
                if os.path.exists(summary_json_file):
                    print("ğŸ“ è¦ç‚¹æ€»ç»“æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    print(f"   JSONæ ¼å¼: {summary_json_file}")
                else:
                    print("ğŸ“ æ­£åœ¨ç”Ÿæˆè¦ç‚¹æ€»ç»“...")
                    
                    # è§£æå­—å¹•
                    if subtitles is None:
                        subtitles = SRTParser.parse_srt_file(subtitle_file)
                        print(f"è§£æåˆ° {len(subtitles)} æ¡å­—å¹•")
                        subtitle_text = SRTParser.format_subtitles_for_llm(subtitles)
                    
                    summary = summarizer.summarize(subtitle_text, stream=args.stream)
                    
                    with open(summary_json_file, 'w', encoding='utf-8') as f:
                        json.dump(summary, f, ensure_ascii=False, indent=2)
                    
                    print()
                    print("âœ… è¦ç‚¹æ€»ç»“å·²ä¿å­˜ï¼š")
                    print(f"   JSONæ ¼å¼: {summary_json_file}")
                    
                    # æ˜¾ç¤ºè¦ç‚¹æ€»ç»“ï¼ˆç»ˆç«¯è¾“å‡ºï¼‰
                    print()
                    print("=" * 80)
                    print("ğŸ“‹ è¦ç‚¹æ€»ç»“é¢„è§ˆï¼š")
                    print("=" * 80)
                    key_points = summary.get('key_points', [])
                    print(f"\nğŸ¯ å…³é”®è¦ç‚¹ï¼ˆå…± {len(key_points)} ä¸ªï¼‰ï¼š\n")
                    for i, point in enumerate(key_points, 1):
                        time = point.get('time', '')
                        title = point.get('title', '')
                        print(f"{i}. [{time}] {title}")
                    print("=" * 80)
                
                # ========== 2. ç”Ÿæˆå®Œæ•´å†…å®¹æ–‡æ¡£ ==========
                print()
                print("=" * 80)
                if os.path.exists(full_content_file):
                    print("ğŸ“š å®Œæ•´å†…å®¹æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    print(f"   Markdownæ ¼å¼: {full_content_file}")
                else:
                    print("ğŸ“š æ­£åœ¨ç”Ÿæˆå®Œæ•´å†…å®¹æ–‡æ¡£...")
                    print("-" * 80)
                    
                    # ä½¿ç”¨é¢„å¤„ç†çš„æ–‡æœ¬ï¼ˆå»é™¤æ—¶é—´æ ‡ç­¾ï¼Œæ™ºèƒ½åˆ†æ®µï¼‰
                    if plain_text is None:
                        print("æ­£åœ¨é¢„å¤„ç†å­—å¹•æ–‡æœ¬...")
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    if args.debug:
                        print(f"[DEBUG] é¢„å¤„ç†åæ–‡æœ¬é•¿åº¦: {len(plain_text)} å­—ç¬¦")
                        print(f"[DEBUG] é¢„å¤„ç†ç¤ºä¾‹:\n{plain_text[:500]}...\n")
                    
                    full_content = summarizer.generate_full_content(
                        plain_text,  # ä½¿ç”¨é¢„å¤„ç†åçš„æ–‡æœ¬
                        video_title=video_title,
                        stream=args.stream
                    )
                    
                    # åˆ›å»ºmarkdownå­ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    os.makedirs(markdown_dir, exist_ok=True)
                    
                    with open(full_content_file, 'w', encoding='utf-8') as f:
                        f.write(full_content)
                    
                    print()
                    print("âœ… å®Œæ•´å†…å®¹å·²ä¿å­˜ï¼š")
                    print(f"   Markdownæ ¼å¼: {full_content_file}")
                
                # ========== 3. ç”Ÿæˆç»ƒä¹ é¢˜ ==========
                print()
                print("=" * 80)
                if os.path.exists(exercises_file):
                    print("ğŸ“ ç»ƒä¹ é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    print(f"   JSONæ ¼å¼: {exercises_file}")
                else:
                    print("ğŸ“ æ­£åœ¨ç”Ÿæˆç»ƒä¹ é¢˜...")
                    print("-" * 80)
                    
                    # é¢„å¤„ç†å­—å¹•æ–‡æœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if plain_text is None:
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    exercises = summarizer.generate_exercises(
                        plain_text,
                        video_title=video_title,
                        stream=args.stream
                    )
                    
                    with open(exercises_file, 'w', encoding='utf-8') as f:
                        json.dump(exercises, f, ensure_ascii=False, indent=2)
                    
                    print()
                    print("âœ… ç»ƒä¹ é¢˜å·²ä¿å­˜ï¼š")
                    print(f"   JSONæ ¼å¼: {exercises_file}")
                    
                    # æ˜¾ç¤ºé¢˜ç›®æ•°é‡ç»Ÿè®¡
                    mc_count = len(exercises.get('multiple_choice', []))
                    sa_count = len(exercises.get('short_answer', []))
                    print(f"   é€‰æ‹©é¢˜: {mc_count} é“")
                    print(f"   ç®€ç­”é¢˜: {sa_count} é“")
                
                # ========== 4. ç”Ÿæˆé¢„è®¾é—®é¢˜ ==========
                print()
                print("=" * 80)
                if os.path.exists(questions_file):
                    print("â“ é¢„è®¾é—®é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    print(f"   JSONæ ¼å¼: {questions_file}")
                else:
                    print("â“ æ­£åœ¨ç”Ÿæˆé¢„è®¾é—®é¢˜...")
                    print("-" * 80)
                    
                    # é¢„å¤„ç†å­—å¹•æ–‡æœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if plain_text is None:
                        plain_text = SRTParser.extract_plain_text(subtitle_file)
                    
                    preset_questions = summarizer.generate_preset_questions(
                        plain_text,
                        video_title=video_title,
                        stream=args.stream
                    )
                    
                    with open(questions_file, 'w', encoding='utf-8') as f:
                        json.dump(preset_questions, f, ensure_ascii=False, indent=2)
                    
                    print()
                    print("âœ… é¢„è®¾é—®é¢˜å·²ä¿å­˜ï¼š")
                    print(f"   JSONæ ¼å¼: {questions_file}")
                    
                    # æ˜¾ç¤ºé—®é¢˜æ•°é‡
                    q_count = len(preset_questions.get('questions', []))
                    print(f"   é—®é¢˜æ•°é‡: {q_count} ä¸ª")
                    
                    # æ˜¾ç¤ºé—®é¢˜é¢„è§ˆ
                    if q_count > 0:
                        print("\n   é—®é¢˜é¢„è§ˆ:")
                        for q in preset_questions.get('questions', []):
                            print(f"   {q.get('id')}. {q.get('question')}")
                
                success_count += 1
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ­¤å­—å¹•æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                if args.debug:
                    import traceback
                    traceback.print_exc()
                failed_count += 1
                # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶ï¼Œè€Œä¸æ˜¯ç›´æ¥é€€å‡º
                continue
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        print()
        print("=" * 80)
        print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")
        print("-" * 80)
        print(f"æ€»å…±å¤„ç†: {total_files} ä¸ªå­—å¹•æ–‡ä»¶")
        print(f"æˆåŠŸ: {success_count} ä¸ª")
        if failed_count > 0:
            print(f"å¤±è´¥: {failed_count} ä¸ª")
        print("=" * 80)
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

